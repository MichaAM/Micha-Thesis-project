<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Thesis Analysis results report</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Micha's Thesis</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Links.html">Analysis</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Thesis Analysis results report</h1>

</div>


<div id="by-micha-amsalem" class="section level2">
<h2>By Micha Amsalem</h2>
</div>
<div id="july-2020" class="section level2">
<h2>July 2020</h2>
<p>This is a thesis analysis report. It will help present a reproducible analysis using R markdown &amp; GitHub pages. The analysis is using a Difference-in-Differences model to evaluate the effect of a treatment.</p>
<div id="getting-r-ready-for-analysis" class="section level3">
<h3>Getting R ready for analysis</h3>
<pre class="r"><code>setwd(&quot;C:/Users/user/Documents/GitHub/Micha-Thesis-project&quot;)
clean_full_df &lt;- read.csv(&quot;clean_full_df.csv&quot;)</code></pre>
<p>Adding relevant packages from R library:</p>
</div>
<div id="the-database" class="section level3">
<h3>The database</h3>
<p>The data base includes all merged files, clean relevant variables and student’s scores in Z-score. First step will be. ### Database dimensions:</p>
<pre class="r"><code>dim(clean_full_df)</code></pre>
<pre><code>## [1] 171639     33</code></pre>
<p>171639 observations and 30 variables</p>
</div>
<div id="summarizing-variables" class="section level3">
<h3>Summarizing variables:</h3>
<pre class="r"><code>summary(clean_full_df)</code></pre>
<pre><code>##       X.4              X.3              X.2              X.1        
##  Min.   :     1   Min.   :     1   Min.   :     1   Min.   :     1  
##  1st Qu.: 42911   1st Qu.: 42911   1st Qu.: 42911   1st Qu.: 42911  
##  Median : 85820   Median : 85820   Median : 85820   Median : 85820  
##  Mean   : 85820   Mean   : 85820   Mean   : 85820   Mean   : 85820  
##  3rd Qu.:128730   3rd Qu.:128730   3rd Qu.:128730   3rd Qu.:128730  
##  Max.   :171639   Max.   :171639   Max.   :171639   Max.   :171639  
##                                                                     
##                    CODE_MOSAD                   CODE_ZEHUT_TALMID 
##  D0266047736N4413624396C:   329   D0041376782N0447474306C:     4  
##  D0108756130N0550706127C:   310   D0225188284N0012215608C:     4  
##  D0266047736N7636887541C:   310   D0225188284N0748418425C:     4  
##  D0108756130N0894513208C:   302   D0225188284N7552989225C:     4  
##  D0567179258N1744455801C:   297   D0380345541N7733812511C:     4  
##  D0567179258N8061001312C:   293   D0607546100N9421219824C:     4  
##  (Other)                :169798   (Other)                :171615  
##    heb.zscore      mat.zscore      eng.zscore      arb.zscore    
##  Min.   :-3.79   Min.   :-2.46   Min.   :-3.24   Min.   :-2.83   
##  1st Qu.:-0.48   1st Qu.:-0.75   1st Qu.:-0.71   1st Qu.:-0.65   
##  Median : 0.26   Median : 0.09   Median : 0.13   Median : 0.22   
##  Mean   : 0.01   Mean   : 0.00   Mean   : 0.00   Mean   : 0.00   
##  3rd Qu.: 0.74   3rd Qu.: 0.82   3rd Qu.: 0.83   3rd Qu.: 0.79   
##  Max.   : 1.58   Max.   : 2.02   Max.   : 1.65   Max.   : 1.70   
##  NA&#39;s   :87490   NA&#39;s   :56476   NA&#39;s   :61802   NA&#39;s   :140393  
##   SHNAT_LIMUD      CODE_MIN       CODE_LEOM     SHNOT_LIMUD_AV  SHNOT_LIMUD_EM
##  Min.   :2008   Min.   :1.000   Min.   :0.000   Min.   : 0.00   Min.   : 0.0  
##  1st Qu.:2008   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:12.00   1st Qu.:12.0  
##  Median :2009   Median :1.000   Median :1.000   Median :12.00   Median :12.0  
##  Mean   :2011   Mean   :1.497   Mean   :1.541   Mean   :12.49   Mean   :12.5  
##  3rd Qu.:2015   3rd Qu.:2.000   3rd Qu.:3.000   3rd Qu.:15.00   3rd Qu.:16.0  
##  Max.   :2016   Max.   :2.000   Max.   :9.000   Max.   :25.00   Max.   :25.0  
##                                                                               
##   CODE_MIGZAR    CODE_SFAT_LIMUDIM CODE_MACHOZ_GEOGRAFI     treat       
##  Min.   :1.000   Min.   :1.000     Min.   :1.000        Min.   :0.0000  
##  1st Qu.:1.000   1st Qu.:1.000     1st Qu.:2.000        1st Qu.:0.0000  
##  Median :1.000   Median :1.000     Median :4.000        Median :1.0000  
##  Mean   :1.528   Mean   :1.277     Mean   :3.808        Mean   :0.5642  
##  3rd Qu.:2.000   3rd Qu.:2.000     3rd Qu.:5.000        3rd Qu.:1.0000  
##  Max.   :6.000   Max.   :2.000     Max.   :7.000        Max.   :1.0000  
##  NA&#39;s   :143     NA&#39;s   :143       NA&#39;s   :143                          
##      after             did          mean_tipuah     tipuah_group  
##  Min.   :0.0000   Min.   :0.0000   Min.   :1.015   Min.   :1.000  
##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:3.293   1st Qu.:1.000  
##  Median :0.0000   Median :0.0000   Median :5.637   Median :2.000  
##  Mean   :0.4275   Mean   :0.2334   Mean   :5.375   Mean   :2.042  
##  3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:7.470   3rd Qu.:3.000  
##  Max.   :1.0000   Max.   :1.0000   Max.   :9.860   Max.   :3.000  
##                                    NA&#39;s   :287     NA&#39;s   :287    
##  dummy_year_2008  dummy_year_2009  dummy_year_2015  dummy_year_2016 
##  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median :0.0000   Median :0.0000   Median :0.0000   Median :0.0000  
##  Mean   :0.2919   Mean   :0.2806   Mean   :0.2042   Mean   :0.2233  
##  3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.0000  
##  Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
##                                                                     
##        X        mean_kids_per_class_by_school_year   ERETS_LEDA   
##  Min.   :   2   Min.   : 3.00                      Min.   :  9.0  
##  1st Qu.:2310   1st Qu.:24.00                      1st Qu.:900.0  
##  Median :5187   Median :27.75                      Median :900.0  
##  Mean   :4938   Mean   :27.70                      Mean   :878.5  
##  3rd Qu.:7200   3rd Qu.:31.50                      3rd Qu.:900.0  
##  Max.   :9952   Max.   :85.00                      Max.   :990.0  
##  NA&#39;s   :192    NA&#39;s   :192                                       
##  erets_leda_ISR    dummy_av_88       dummy_em_88      
##  Min.   :0.0000   Min.   :0.00000   Min.   :0.000000  
##  1st Qu.:1.0000   1st Qu.:0.00000   1st Qu.:0.000000  
##  Median :1.0000   Median :0.00000   Median :0.000000  
##  Mean   :0.9512   Mean   :0.00832   Mean   :0.006997  
##  3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.000000  
##  Max.   :1.0000   Max.   :1.00000   Max.   :1.000000  
## </code></pre>
<p>Next, use str function for clean overlook on variables:</p>
<pre class="r"><code>str(clean_full_df)</code></pre>
<pre><code>## &#39;data.frame&#39;:    171639 obs. of  33 variables:
##  $ X.4                               : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ X.3                               : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ X.2                               : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ X.1                               : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ CODE_MOSAD                        : Factor w/ 1943 levels &quot;D0108756130N0003209990C&quot;,..: 279 735 1557 1087 991 1077 251 1684 735 1348 ...
##  $ CODE_ZEHUT_TALMID                 : Factor w/ 171259 levels &quot;D0007155831N0002673851C&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
##  $ heb.zscore                        : num  NA 0.367 -0.668 -0.648 0.599 ...
##  $ mat.zscore                        : num  NA -0.5281 0.2383 -0.0668 0.1076 ...
##  $ eng.zscore                        : num  0.665 NA NA NA NA ...
##  $ arb.zscore                        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ SHNAT_LIMUD                       : int  2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 ...
##  $ CODE_MIN                          : int  1 1 2 2 1 2 2 2 1 1 ...
##  $ CODE_LEOM                         : int  3 1 1 1 1 1 1 1 1 1 ...
##  $ SHNOT_LIMUD_AV                    : int  12 0 12 11 10 12 11 12 0 14 ...
##  $ SHNOT_LIMUD_EM                    : int  12 0 12 12 12 12 12 13 0 12 ...
##  $ CODE_MIGZAR                       : int  2 1 1 1 1 1 1 1 1 1 ...
##  $ CODE_SFAT_LIMUDIM                 : int  2 1 1 1 1 1 1 1 1 1 ...
##  $ CODE_MACHOZ_GEOGRAFI              : int  2 6 3 4 4 4 2 3 6 4 ...
##  $ treat                             : int  1 0 0 1 1 0 1 0 0 0 ...
##  $ after                             : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ did                               : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ mean_tipuah                       : num  5.29 6.87 6.37 7.46 7.44 ...
##  $ tipuah_group                      : int  2 2 2 3 3 2 3 2 2 1 ...
##  $ dummy_year_2008                   : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ dummy_year_2009                   : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ dummy_year_2015                   : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ dummy_year_2016                   : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ X                                 : int  1291 3977 7869 5637 5201 5589 1155 8502 3977 6863 ...
##  $ mean_kids_per_class_by_school_year: num  32.7 10 21.5 34 27.7 ...
##  $ ERETS_LEDA                        : int  900 900 900 900 900 900 900 900 900 900 ...
##  $ erets_leda_ISR                    : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ dummy_av_88                       : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ dummy_em_88                       : int  0 0 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
</div>
<div id="analysis" class="section level1">
<h1>Analysis</h1>
<p>First analysis will make use of the general diff-in-diff regression for evaluating the difference between treatment and control groups, before and after the treatment, without fixed effects, additional variables or splitting database. The regression will estimate did estimator for each of the exam’s subjects the students took part in: Hebrew, Math, English and Arabic for the years 2008-2009 and for the year 2015-2016.</p>
<div id="general-did-astimate" class="section level2">
<h2>General DID astimate</h2>
<pre class="r"><code>didreg.heb &lt;- lm(heb.zscore ~ treat + after + did, data = clean_full_df)
summary(didreg.heb)</code></pre>
<pre><code>## 
## Call:
## lm(formula = heb.zscore ~ treat + after + did, data = clean_full_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.8200 -0.4841  0.2484  0.7326  1.5967 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.015296   0.007705   1.985 0.047106 *  
## treat       -0.006106   0.010814  -0.565 0.572362    
## after       -0.033474   0.009851  -3.398 0.000680 ***
## did          0.049422   0.013955   3.542 0.000398 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.991 on 84145 degrees of freedom
##   (87490 observations deleted due to missingness)
## Multiple R-squared:  0.0003119,  Adjusted R-squared:  0.0002762 
## F-statistic:  8.75 on 3 and 84145 DF,  p-value: 8.468e-06</code></pre>
<pre class="r"><code>didreg.mat &lt;- lm(mat.zscore ~ treat + after + did, data = clean_full_df)
summary(didreg.mat)</code></pre>
<pre><code>## 
## Call:
## lm(formula = mat.zscore ~ treat + after + did, data = clean_full_df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.50751 -0.75015  0.09149  0.81005  2.04688 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.089315   0.007088  12.601  &lt; 2e-16 ***
## treat       -0.138765   0.009330 -14.872  &lt; 2e-16 ***
## after       -0.055263   0.009057  -6.102 1.05e-09 ***
## did          0.078873   0.012054   6.544 6.03e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9949 on 115159 degrees of freedom
##   (56476 observations deleted due to missingness)
## Multiple R-squared:  0.002465,   Adjusted R-squared:  0.002439 
## F-statistic: 94.84 on 3 and 115159 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>didreg.eng &lt;- lm(eng.zscore ~ treat + after + did, data = clean_full_df)
summary(didreg.eng)</code></pre>
<pre><code>## 
## Call:
## lm(formula = eng.zscore ~ treat + after + did, data = clean_full_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.3023 -0.7090  0.1384  0.8337  1.6883 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.065610   0.007114   9.222   &lt;2e-16 ***
## treat       -0.109610   0.009353 -11.719   &lt;2e-16 ***
## after       -0.009603   0.009428  -1.019    0.308    
## did          0.013190   0.012347   1.068    0.285    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9971 on 109833 degrees of freedom
##   (61802 observations deleted due to missingness)
## Multiple R-squared:  0.002549,   Adjusted R-squared:  0.002522 
## F-statistic: 93.56 on 3 and 109833 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>didreg.arb &lt;- lm(arb.zscore ~ treat + after + did, data = clean_full_df)
summary(didreg.arb)</code></pre>
<pre><code>## 
## Call:
## lm(formula = arb.zscore ~ treat + after + did, data = clean_full_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.9689 -0.6495  0.2097  0.7830  1.7492 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.20967    0.01807  11.605  &lt; 2e-16 ***
## treat       -0.26381    0.02059 -12.809  &lt; 2e-16 ***
## after       -0.07538    0.02265  -3.328 0.000876 ***
## did          0.07873    0.02621   3.004 0.002665 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9911 on 31242 degrees of freedom
##   (140393 observations deleted due to missingness)
## Multiple R-squared:  0.009342,   Adjusted R-squared:  0.009247 
## F-statistic:  98.2 on 3 and 31242 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>General DID analysis summary table:</p>
<pre class="r"><code>stargazer(didreg.heb, didreg.mat, didreg.eng, didreg.arb, title=&quot;DiD Regression Results&quot;, align=TRUE, type = &quot;text&quot;)</code></pre>
<pre><code>## 
## DiD Regression Results
## ============================================================================================================================
##                                                               Dependent variable:                                           
##                     --------------------------------------------------------------------------------------------------------
##                            heb.zscore                mat.zscore                 eng.zscore                arb.zscore        
##                               (1)                       (2)                        (3)                        (4)           
## ----------------------------------------------------------------------------------------------------------------------------
## treat                        -0.006                  -0.139***                  -0.110***                  -0.264***        
##                             (0.011)                   (0.009)                    (0.009)                    (0.021)         
##                                                                                                                             
## after                      -0.033***                 -0.055***                    -0.010                   -0.075***        
##                             (0.010)                   (0.009)                    (0.009)                    (0.023)         
##                                                                                                                             
## did                         0.049***                  0.079***                    0.013                    0.079***         
##                             (0.014)                   (0.012)                    (0.012)                    (0.026)         
##                                                                                                                             
## Constant                    0.015**                   0.089***                   0.066***                  0.210***         
##                             (0.008)                   (0.007)                    (0.007)                    (0.018)         
##                                                                                                                             
## ----------------------------------------------------------------------------------------------------------------------------
## Observations                 84,149                   115,163                    109,837                    31,246          
## R2                           0.0003                    0.002                      0.003                      0.009          
## Adjusted R2                  0.0003                    0.002                      0.003                      0.009          
## Residual Std. Error    0.991 (df = 84145)       0.995 (df = 115159)        0.997 (df = 109833)        0.991 (df = 31242)    
## F Statistic         8.750*** (df = 3; 84145) 94.843*** (df = 3; 115159) 93.557*** (df = 3; 109833) 98.203*** (df = 3; 31242)
## ============================================================================================================================
## Note:                                                                                            *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>In the table above, did estimators for Hebrew, Math and Arabic average scores are significant. English is not significant.</p>
</div>
</div>
<div id="spliting-by-schools-sectors---jewish-sector-vs-arab-sector" class="section level1">
<h1>Spliting by school’s sectors - Jewish sector vs Arab sector</h1>
<p>It is usually acceptable showing those results by splitting the database by language - Hebrew speaking schools and Arabic speaking schools. This split is done by using the CODE_MIGZAR column in the database.</p>
<pre class="r"><code>clean_full_df_heb &lt;- clean_full_df %&gt;%
  filter(CODE_MIGZAR == &quot;1&quot;)
clean_full_df_arb &lt;- clean_full_df %&gt;%
  filter(CODE_MIGZAR != &quot;1&quot;)</code></pre>
<p>So, after the split, We produce those 2 tables that sums the did regression analysis results by the 2 data sets:</p>
<div id="hebrew-speaking-schools---jewish-sector" class="section level2">
<h2>Hebrew speaking schools - Jewish sector</h2>
<pre class="r"><code>didreg.heb.Hebrew &lt;- lm(heb.zscore ~ treat + after + did, data = clean_full_df_heb)
summary(didreg.heb.Hebrew)</code></pre>
<pre><code>## 
## Call:
## lm(formula = heb.zscore ~ treat + after + did, data = clean_full_df_heb)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.8200 -0.4841  0.2494  0.7314  1.5954 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.016515   0.007708   2.143 0.032139 *  
## treat       -0.007324   0.010814  -0.677 0.498250    
## after       -0.033404   0.009855  -3.390 0.000700 ***
## did          0.049353   0.013954   3.537 0.000405 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9906 on 84089 degrees of freedom
##   (39892 observations deleted due to missingness)
## Multiple R-squared:  0.0002966,  Adjusted R-squared:  0.000261 
## F-statistic: 8.317 on 3 and 84089 DF,  p-value: 1.584e-05</code></pre>
<pre class="r"><code>didreg.mat.Hebrew &lt;- lm(mat.zscore ~ treat + after + did, data = clean_full_df_heb)
summary(didreg.mat.Hebrew)</code></pre>
<pre><code>## 
## Call:
## lm(formula = mat.zscore ~ treat + after + did, data = clean_full_df_heb)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.5914 -0.7286  0.1295  0.8056  1.9070 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.138742   0.007637  18.167  &lt; 2e-16 ***
## treat        0.024519   0.010750   2.281   0.0226 *  
## after       -0.065000   0.009798  -6.634 3.29e-11 ***
## did          0.028514   0.013888   2.053   0.0401 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9859 on 83978 degrees of freedom
##   (40003 observations deleted due to missingness)
## Multiple R-squared:  0.00115,    Adjusted R-squared:  0.001114 
## F-statistic: 32.22 on 3 and 83978 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>didreg.eng.Hebrew &lt;- lm(eng.zscore ~ treat + after + did, data = clean_full_df_heb)
summary(didreg.eng.Hebrew)</code></pre>
<pre><code>## 
## Call:
## lm(formula = eng.zscore ~ treat + after + did, data = clean_full_df_heb)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.3623 -0.7214  0.1356  0.8392  1.6725 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.125602   0.008092  15.522  &lt; 2e-16 ***
## treat       -0.072565   0.011089  -6.544 6.04e-11 ***
## after       -0.042326   0.010659  -3.971 7.17e-05 ***
## did         -0.035318   0.014566  -2.425   0.0153 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9978 on 77456 degrees of freedom
##   (46525 observations deleted due to missingness)
## Multiple R-squared:  0.003165,   Adjusted R-squared:  0.003127 
## F-statistic: 81.98 on 3 and 77456 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="summary-analysis-table-for-hebrew-speaking" class="section level2">
<h2>Summary analysis table for Hebrew speaking</h2>
<pre class="r"><code>stargazer(didreg.heb.Hebrew, didreg.mat.Hebrew, didreg.eng.Hebrew, title=&quot;DiD Regression Results for Hebrew&quot;, align=TRUE, type = &quot;text&quot;)</code></pre>
<pre><code>## 
## DiD Regression Results for Hebrew
## ================================================================================================
##                                                 Dependent variable:                             
##                     ----------------------------------------------------------------------------
##                            heb.zscore               mat.zscore                eng.zscore        
##                               (1)                       (2)                       (3)           
## ------------------------------------------------------------------------------------------------
## treat                        -0.007                   0.025**                  -0.073***        
##                             (0.011)                   (0.011)                   (0.011)         
##                                                                                                 
## after                      -0.033***                 -0.065***                 -0.042***        
##                             (0.010)                   (0.010)                   (0.011)         
##                                                                                                 
## did                         0.049***                  0.029**                  -0.035**         
##                             (0.014)                   (0.014)                   (0.015)         
##                                                                                                 
## Constant                    0.017**                  0.139***                  0.126***         
##                             (0.008)                   (0.008)                   (0.008)         
##                                                                                                 
## ------------------------------------------------------------------------------------------------
## Observations                 84,093                   83,982                    77,460          
## R2                           0.0003                    0.001                     0.003          
## Adjusted R2                  0.0003                    0.001                     0.003          
## Residual Std. Error    0.991 (df = 84089)       0.986 (df = 83978)        0.998 (df = 77456)    
## F Statistic         8.317*** (df = 3; 84089) 32.222*** (df = 3; 83978) 81.984*** (df = 3; 77456)
## ================================================================================================
## Note:                                                                *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>In the table we can see that, for hebrew speaking schools only, the did coefficients are significant for each subject. In English it looks like that the the effect of the treatment is negative. This result can change when adding fixed effects or additional variables.</p>
</div>
<div id="arabic-speaking-schools---arabic-sector" class="section level2">
<h2>Arabic speaking schools - Arabic sector</h2>
<p>Now, we test the same regression on the Arabic speaking sector only</p>
<pre class="r"><code>didreg.mat.Arabic &lt;- lm(mat.zscore ~ treat + after + did, data = clean_full_df_arb)
summary(didreg.mat.Arabic)</code></pre>
<pre><code>## 
## Call:
## lm(formula = mat.zscore ~ treat + after + did, data = clean_full_df_arb)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.24353 -0.74568  0.01487  0.74522  2.31520 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.17466    0.01737 -10.053  &lt; 2e-16 ***
## treat       -0.23944    0.01982 -12.082  &lt; 2e-16 ***
## after        0.02461    0.02172   1.133  0.25726    
## did          0.07350    0.02515   2.923  0.00347 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9489 on 31090 degrees of freedom
##   (16417 observations deleted due to missingness)
## Multiple R-squared:  0.01051,    Adjusted R-squared:  0.01042 
## F-statistic: 110.1 on 3 and 31090 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>didreg.eng.Arabic &lt;- lm(eng.zscore ~ treat + after + did, data = clean_full_df_arb)
summary(didreg.eng.Arabic)</code></pre>
<pre><code>## 
## Call:
## lm(formula = eng.zscore ~ treat + after + did, data = clean_full_df_arb)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.0185 -0.6808  0.1517  0.7987  1.6268 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.14190    0.01483  -9.567  &lt; 2e-16 ***
## treat       -0.07625    0.01790  -4.261 2.04e-05 ***
## after        0.09147    0.02006   4.559 5.15e-06 ***
## did          0.05674    0.02403   2.362   0.0182 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9835 on 32331 degrees of freedom
##   (15176 observations deleted due to missingness)
## Multiple R-squared:  0.004877,   Adjusted R-squared:  0.004784 
## F-statistic: 52.81 on 3 and 32331 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>didreg.arb.Arabic &lt;- lm(arb.zscore ~ treat + after + did, data = clean_full_df_arb)
summary(didreg.arb.Arabic)</code></pre>
<pre><code>## 
## Call:
## lm(formula = arb.zscore ~ treat + after + did, data = clean_full_df_arb)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.9689 -0.6483  0.2108  0.7841  1.7503 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.21642    0.01819  11.895  &lt; 2e-16 ***
## treat       -0.27169    0.02071 -13.120  &lt; 2e-16 ***
## after       -0.08209    0.02277  -3.605 0.000313 ***
## did          0.08547    0.02632   3.247 0.001166 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9912 on 31130 degrees of freedom
##   (16377 observations deleted due to missingness)
## Multiple R-squared:  0.009663,   Adjusted R-squared:  0.009567 
## F-statistic: 101.2 on 3 and 31130 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>stargazer(didreg.arb.Arabic, didreg.mat.Arabic, didreg.eng.Arabic, title=&quot;DiD Regression Results for Arabic&quot;, align=TRUE, type = &quot;text&quot;)</code></pre>
<pre><code>## 
## DiD Regression Results for Arabic
## ===================================================================================================
##                                                   Dependent variable:                              
##                     -------------------------------------------------------------------------------
##                             arb.zscore                 mat.zscore                eng.zscore        
##                                (1)                        (2)                        (3)           
## ---------------------------------------------------------------------------------------------------
## treat                       -0.272***                  -0.239***                  -0.076***        
##                              (0.021)                    (0.020)                    (0.018)         
##                                                                                                    
## after                       -0.082***                    0.025                    0.091***         
##                              (0.023)                    (0.022)                    (0.020)         
##                                                                                                    
## did                          0.085***                   0.074***                   0.057**         
##                              (0.026)                    (0.025)                    (0.024)         
##                                                                                                    
## Constant                     0.216***                  -0.175***                  -0.142***        
##                              (0.018)                    (0.017)                    (0.015)         
##                                                                                                    
## ---------------------------------------------------------------------------------------------------
## Observations                  31,134                     31,094                    32,335          
## R2                            0.010                      0.011                      0.005          
## Adjusted R2                   0.010                      0.010                      0.005          
## Residual Std. Error     0.991 (df = 31130)         0.949 (df = 31090)        0.984 (df = 32331)    
## F Statistic         101.243*** (df = 3; 31130) 110.099*** (df = 3; 31090) 52.813*** (df = 3; 32331)
## ===================================================================================================
## Note:                                                                   *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>We can see that all 3 coefficients of did is positive and significant for the level of 1%. It reflects a positive effect of the treatment on the Arabic speaking sector.</p>
</div>
<div id="adding-fixed-effects-to-the-did-regression" class="section level2">
<h2>Adding fixed effects to the DID regression</h2>
<p>I use 2 fixed effects in the regression: Time fixed effect by dummy variables and school fixed effect by “plm” function. This analysis will remove any effect which is due to years unobserved effects and schools unobserved characteristics.</p>
<p>Creat the dummy variables:</p>
<pre class="r"><code>clean_full_df$dummy_year_2008 &lt;- ifelse(clean_full_df$SHNAT_LIMUD == &quot;2008&quot;, &quot;1&quot;, &quot;0&quot;)
clean_full_df$dummy_year_2009 &lt;- ifelse(clean_full_df$SHNAT_LIMUD  == &quot;2009&quot;, &quot;1&quot;, &quot;0&quot;)
clean_full_df$dummy_year_2015 &lt;- ifelse(clean_full_df$SHNAT_LIMUD  == &quot;2015&quot;, &quot;1&quot;, &quot;0&quot;)
clean_full_df$dummy_year_2016 &lt;- ifelse(clean_full_df$SHNAT_LIMUD  == &quot;2016&quot;, &quot;1&quot;, &quot;0&quot;)</code></pre>
</div>
<div id="run-the-did-with-fixed-effects-by-sectorhebrewarabic" class="section level2">
<h2>Run the DID with Fixed Effects by sector(Hebrew/Arabic)</h2>
<div id="did-with-fixed-effects-for-the-jewish-sector" class="section level3">
<h3>DID with Fixed Effects for the Jewish sector :</h3>
<pre class="r"><code>FE.heb.Hebrew &lt;- plm(heb.zscore ~ did + factor(SHNAT_LIMUD)-1, data = clean_full_df_heb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.heb.Hebrew)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = heb.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = clean_full_df_heb, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1305, T = 1-277, N = 84093
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -4.23589 -0.45084  0.19251  0.64580  2.95124 
## 
## Coefficients: (1 dropped because of singularities)
##                           Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                     -0.0017185  0.0181698 -0.0946    0.9246    
## factor(SHNAT_LIMUD)2008  0.1204372  0.0166750  7.2226 5.144e-13 ***
## factor(SHNAT_LIMUD)2009  0.0327138  0.0201124  1.6265    0.1038    
## factor(SHNAT_LIMUD)2015 -0.0003424  0.0190971 -0.0179    0.9857    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    70966
## Residual Sum of Squares: 70893
## R-Squared:      0.001036
## Adj. R-Squared: -0.014748
## F-statistic: 21.4638 on 4 and 82784 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.mat.Hebrew &lt;- plm(mat.zscore ~ did + factor(SHNAT_LIMUD)-1, data = clean_full_df_heb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.mat.Hebrew)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = mat.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = clean_full_df_heb, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1308, T = 1-278, N = 83982
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -3.128202 -0.612123  0.080871  0.672259  2.905497 
## 
## Coefficients: (1 dropped because of singularities)
##                          Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                     -0.013983   0.017361 -0.8054   0.42058    
## factor(SHNAT_LIMUD)2008  0.125791   0.015950  7.8867 3.140e-15 ***
## factor(SHNAT_LIMUD)2009  0.094080   0.019265  4.8835 1.044e-06 ***
## factor(SHNAT_LIMUD)2015  0.035789   0.018262  1.9598   0.05002 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    64690
## Residual Sum of Squares: 64581
## R-Squared:      0.0016913
## Adj. R-Squared: -0.01414
## F-statistic: 35.015 on 4 and 82670 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.eng.Hebrew &lt;- plm(eng.zscore ~ did + factor(SHNAT_LIMUD)-1, data = clean_full_df_heb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.eng.Hebrew)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = eng.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = clean_full_df_heb, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1042, T = 1-295, N = 77460
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -3.89411 -0.62769  0.10846  0.69293  3.23548 
## 
## Coefficients: (1 dropped because of singularities)
##                           Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                     -0.0297389  0.0183645 -1.6194 0.1053730    
## factor(SHNAT_LIMUD)2008  0.0875723  0.0179904  4.8677 1.131e-06 ***
## factor(SHNAT_LIMUD)2009 -0.0013743  0.0221394 -0.0621 0.9505036    
## factor(SHNAT_LIMUD)2015  0.0723379  0.0207225  3.4908 0.0004819 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    63819
## Residual Sum of Squares: 63764
## R-Squared:      0.00086891
## Adj. R-Squared: -0.012795
## F-statistic: 16.6137 on 4 and 76414 DF, p-value: 1.2876e-13</code></pre>
<p>Fixed effects summary table for Jewish sector:</p>
<pre class="r"><code>stargazer(FE.heb.Hebrew, FE.mat.Hebrew, FE.eng.Hebrew, title=&quot;Year &amp; School fixed effect did regression -  Hebrew&quot;, align=TRUE, type = &quot;text&quot;)</code></pre>
<pre><code>## 
## Year &amp; School fixed effect did regression - Hebrew
## =====================================================================================================
##                                                      Dependent variable:                             
##                         -----------------------------------------------------------------------------
##                                heb.zscore                mat.zscore                eng.zscore        
##                                    (1)                       (2)                       (3)           
## -----------------------------------------------------------------------------------------------------
## did                              -0.002                    -0.014                    -0.030          
##                                  (0.018)                   (0.017)                   (0.018)         
##                                                                                                      
## factor(SHNAT_LIMUD)2008         0.120***                  0.126***                  0.088***         
##                                  (0.017)                   (0.016)                   (0.018)         
##                                                                                                      
## factor(SHNAT_LIMUD)2009           0.033                   0.094***                   -0.001          
##                                  (0.020)                   (0.019)                   (0.022)         
##                                                                                                      
## factor(SHNAT_LIMUD)2015          -0.0003                   0.036*                   0.072***         
##                                  (0.019)                   (0.018)                   (0.021)         
##                                                                                                      
## -----------------------------------------------------------------------------------------------------
## Observations                     84,093                    83,982                    77,460          
## R2                                0.001                     0.002                     0.001          
## Adjusted R2                      -0.015                    -0.014                    -0.013          
## F Statistic             21.464*** (df = 4; 82784) 35.015*** (df = 4; 82670) 16.614*** (df = 4; 76414)
## =====================================================================================================
## Note:                                                                     *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
<div id="did-with-fixed-effects-for-the-arabic-sector" class="section level3">
<h3>DID with Fixed Effects for the Arabic sector :</h3>
<pre class="r"><code>FE.arb.Arabic &lt;- plm(arb.zscore ~ did + factor(SHNAT_LIMUD)-1, data = clean_full_df_arb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.arb.Arabic)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = arb.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = clean_full_df_arb, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 340, T = 9-304, N = 31134
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -3.25002 -0.59038  0.15017  0.67851  2.49810 
## 
## Coefficients: (1 dropped because of singularities)
##                          Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                      0.204238   0.032054  6.3717 1.895e-10 ***
## factor(SHNAT_LIMUD)2008  0.067373   0.028399  2.3724   0.01768 *  
## factor(SHNAT_LIMUD)2009  0.067138   0.041601  1.6138   0.10657    
## factor(SHNAT_LIMUD)2015 -0.150270   0.035803 -4.1971 2.711e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    25892
## Residual Sum of Squares: 25839
## R-Squared:      0.0020518
## Adj. R-Squared: -0.0090653
## F-statistic: 15.8263 on 4 and 30790 DF, p-value: 6.0347e-13</code></pre>
<pre class="r"><code>FE.mat.Arabic &lt;- plm(mat.zscore ~ did + factor(SHNAT_LIMUD)-1, data = clean_full_df_arb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.mat.Arabic)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = mat.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = clean_full_df_arb, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 341, T = 9-319, N = 31094
## 
## Residuals:
##       Min.    1st Qu.     Median    3rd Qu.       Max. 
## -2.7780835 -0.6225770  0.0086372  0.6191933  2.5790993 
## 
## Coefficients: (1 dropped because of singularities)
##                          Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                      0.127919   0.029692  4.3082 1.651e-05 ***
## factor(SHNAT_LIMUD)2008 -0.169917   0.026224 -6.4793 9.352e-11 ***
## factor(SHNAT_LIMUD)2009 -0.095934   0.039030 -2.4580   0.01398 *  
## factor(SHNAT_LIMUD)2015 -0.218083   0.034085 -6.3983 1.594e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    22185
## Residual Sum of Squares: 22037
## R-Squared:      0.0066859
## Adj. R-Squared: -0.0044267
## F-statistic: 51.7421 on 4 and 30749 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.eng.Arabic &lt;- plm(eng.zscore ~ did + factor(SHNAT_LIMUD)-1, data = clean_full_df_arb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.eng.Arabic)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = eng.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = clean_full_df_arb, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 358, T = 5-308, N = 32335
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -3.240600 -0.583558  0.095993  0.656941  2.590821 
## 
## Coefficients: (1 dropped because of singularities)
##                          Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                      0.106460   0.032508  3.2749 0.0010582 ** 
## factor(SHNAT_LIMUD)2008 -0.084306   0.036107 -2.3349 0.0195553 *  
## factor(SHNAT_LIMUD)2009 -0.206586   0.038448 -5.3732  7.79e-08 ***
## factor(SHNAT_LIMUD)2015 -0.118874   0.034698 -3.4260 0.0006133 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    25208
## Residual Sum of Squares: 25072
## R-Squared:      0.0054287
## Adj. R-Squared: -0.0058008
## F-statistic: 43.6299 on 4 and 31973 DF, p-value: &lt; 2.22e-16</code></pre>
<p>Fixed effects summary table for Arabic sector:</p>
<pre class="r"><code>stargazer(FE.arb.Arabic, FE.mat.Arabic, FE.eng.Arabic, title=&quot;Year &amp; School fixed effect did regression -  Arabic&quot;, align=TRUE, type = &quot;text&quot;)</code></pre>
<pre><code>## 
## Year &amp; School fixed effect did regression - Arabic
## =====================================================================================================
##                                                      Dependent variable:                             
##                         -----------------------------------------------------------------------------
##                                arb.zscore                mat.zscore                eng.zscore        
##                                    (1)                       (2)                       (3)           
## -----------------------------------------------------------------------------------------------------
## did                             0.204***                  0.128***                  0.106***         
##                                  (0.032)                   (0.030)                   (0.033)         
##                                                                                                      
## factor(SHNAT_LIMUD)2008          0.067**                  -0.170***                 -0.084**         
##                                  (0.028)                   (0.026)                   (0.036)         
##                                                                                                      
## factor(SHNAT_LIMUD)2009           0.067                   -0.096**                  -0.207***        
##                                  (0.042)                   (0.039)                   (0.038)         
##                                                                                                      
## factor(SHNAT_LIMUD)2015         -0.150***                 -0.218***                 -0.119***        
##                                  (0.036)                   (0.034)                   (0.035)         
##                                                                                                      
## -----------------------------------------------------------------------------------------------------
## Observations                     31,134                    31,094                    32,335          
## R2                                0.002                     0.007                     0.005          
## Adjusted R2                      -0.009                    -0.004                    -0.006          
## F Statistic             15.826*** (df = 4; 30790) 51.742*** (df = 4; 30749) 43.630*** (df = 4; 31973)
## =====================================================================================================
## Note:                                                                     *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
<div id="tidy-the-database-to-final.df" class="section level3">
<h3>Tidy the database to final.df</h3>
<pre class="r"><code>final_df &lt;- clean_full_df %&gt;%
  select(CODE_MOSAD, SHNAT_LIMUD, CODE_ZEHUT_TALMID, heb.zscore, mat.zscore, eng.zscore, arb.zscore,
         CODE_MIN, SHNOT_LIMUD_AV, SHNOT_LIMUD_EM, dummy_av_88, dummy_em_88, CODE_MIGZAR, CODE_MACHOZ_GEOGRAFI,
         treat, after, did, mean_tipuah, tipuah_group, dummy_year_2008, dummy_year_2009, dummy_year_2015, dummy_year_2016,
         mean_kids_per_class_by_school_year, erets_leda_ISR)</code></pre>
</div>
</div>
<div id="split-database-to-regress-by-counties" class="section level2">
<h2>Split database to regress by counties</h2>
<pre class="r"><code>final_df_zafon_darom &lt;- final_df %&gt;%
  filter(CODE_MACHOZ_GEOGRAFI == &quot;1&quot; | CODE_MACHOZ_GEOGRAFI == &quot;6&quot; | CODE_MACHOZ_GEOGRAFI == &quot;8&quot;) 

final_df_rest &lt;- final_df %&gt;%
  filter(CODE_MACHOZ_GEOGRAFI == &quot;2&quot; | CODE_MACHOZ_GEOGRAFI == &quot;3&quot; | CODE_MACHOZ_GEOGRAFI == &quot;4&quot; | CODE_MACHOZ_GEOGRAFI == &quot;5&quot; | CODE_MACHOZ_GEOGRAFI == &quot;7&quot;)</code></pre>
<div id="regression-mahoz-darom-zafon-only-with-fixed-effects" class="section level3">
<h3>regression mahoz darom + zafon only with fixed effects</h3>
<pre class="r"><code>FE.heb.zafon_darom &lt;- plm(heb.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_zafon_darom, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.heb.zafon_darom)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = heb.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_zafon_darom, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 379, T = 2-224, N = 23238
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -4.09518 -0.48081  0.19149  0.66813  2.77855 
## 
## Coefficients: (1 dropped because of singularities)
##                          Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                     -0.063005   0.037718 -1.6704 0.0948478 .  
## factor(SHNAT_LIMUD)2008  0.051453   0.037425  1.3748 0.1691966    
## factor(SHNAT_LIMUD)2009  0.045641   0.040666  1.1223 0.2617327    
## factor(SHNAT_LIMUD)2015 -0.111024   0.032910 -3.3735 0.0007433 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    20616
## Residual Sum of Squares: 20525
## R-Squared:      0.0043949
## Adj. R-Squared: -0.012246
## F-statistic: 25.2221 on 4 and 22855 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.mat.zafon_darom &lt;- plm(mat.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_zafon_darom, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.mat.zafon_darom)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = mat.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_zafon_darom, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 446, T = 2-264, N = 29643
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -3.044125 -0.630778  0.046345  0.666675  3.048617 
## 
## Coefficients: (1 dropped because of singularities)
##                          Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                     -0.096732   0.033953 -2.8490  0.004389 ** 
## factor(SHNAT_LIMUD)2008 -0.034786   0.033868 -1.0271  0.304387    
## factor(SHNAT_LIMUD)2009  0.086987   0.037486  2.3205  0.020320 *  
## factor(SHNAT_LIMUD)2015 -0.124703   0.028509 -4.3742 1.223e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    22867
## Residual Sum of Squares: 22696
## R-Squared:      0.0074752
## Adj. R-Squared: -0.0077902
## F-statistic: 54.9671 on 4 and 29193 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.eng.zafon_darom &lt;- plm(eng.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_zafon_darom, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.eng.zafon_darom)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = eng.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_zafon_darom, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 335, T = 1-235, N = 24354
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -3.328028 -0.653611  0.075422  0.706565  3.098278 
## 
## Coefficients: (1 dropped because of singularities)
##                           Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                     -0.0084595  0.0641442 -0.1319    0.8951    
## factor(SHNAT_LIMUD)2008  0.0573128  0.0679648  0.8433    0.3991    
## factor(SHNAT_LIMUD)2009 -0.0077658  0.0675288 -0.1150    0.9084    
## factor(SHNAT_LIMUD)2015  0.2146901  0.0424554  5.0568 4.294e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    20962
## Residual Sum of Squares: 20910
## R-Squared:      0.0024836
## Adj. R-Squared: -0.011556
## F-statistic: 14.9481 on 4 and 24015 DF, p-value: 3.3207e-12</code></pre>
<pre class="r"><code>FE.arb.zafon_darom &lt;- plm(arb.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_zafon_darom, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.arb.zafon_darom)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = arb.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_zafon_darom, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 71, T = 8-265, N = 6546
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -2.53918 -0.81126  0.06060  0.81501  2.49810 
## 
## Coefficients: (1 dropped because of singularities)
##                         Estimate Std. Error t-value Pr(&gt;|t|)    
## did                     -0.48671    0.35069 -1.3879   0.1652    
## factor(SHNAT_LIMUD)2008 -0.68523    0.35452 -1.9328   0.0533 .  
## factor(SHNAT_LIMUD)2009 -0.58623    0.36280 -1.6159   0.1062    
## factor(SHNAT_LIMUD)2015 -0.62613    0.10714 -5.8441 5.34e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    6942.8
## Residual Sum of Squares: 6822.2
## R-Squared:      0.017364
## Adj. R-Squared: 0.0061272
## F-statistic: 28.5874 on 4 and 6471 DF, p-value: &lt; 2.22e-16</code></pre>
<p>Summary table for mahoz darom + zafon with fixed effects:</p>
<pre class="r"><code>stargazer(FE.heb.zafon_darom, FE.mat.zafon_darom, FE.eng.zafon_darom, FE.arb.zafon_darom, title=&quot;Year &amp; School fixed effect did regression -  north + south&quot;, align=TRUE, type = &quot;text&quot;)</code></pre>
<pre><code>## 
## Year &amp; School fixed effect did regression - north + south
## ==============================================================================================================================
##                                                                  Dependent variable:                                          
##                         ------------------------------------------------------------------------------------------------------
##                                heb.zscore                mat.zscore                eng.zscore                arb.zscore       
##                                    (1)                       (2)                       (3)                      (4)           
## ------------------------------------------------------------------------------------------------------------------------------
## did                              -0.063*                  -0.097***                  -0.008                    -0.487         
##                                  (0.038)                   (0.034)                   (0.064)                  (0.351)         
##                                                                                                                               
## factor(SHNAT_LIMUD)2008           0.051                    -0.035                     0.057                   -0.685*         
##                                  (0.037)                   (0.034)                   (0.068)                  (0.355)         
##                                                                                                                               
## factor(SHNAT_LIMUD)2009           0.046                    0.087**                   -0.008                    -0.586         
##                                  (0.041)                   (0.037)                   (0.068)                  (0.363)         
##                                                                                                                               
## factor(SHNAT_LIMUD)2015         -0.111***                 -0.125***                 0.215***                 -0.626***        
##                                  (0.033)                   (0.029)                   (0.042)                  (0.107)         
##                                                                                                                               
## ------------------------------------------------------------------------------------------------------------------------------
## Observations                     23,238                    29,643                    24,354                    6,546          
## R2                                0.004                     0.007                     0.002                    0.017          
## Adjusted R2                      -0.012                    -0.008                    -0.012                    0.006          
## F Statistic             25.222*** (df = 4; 22855) 54.967*** (df = 4; 29193) 14.948*** (df = 4; 24015) 28.587*** (df = 4; 6471)
## ==============================================================================================================================
## Note:                                                                                              *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>I wanted to check in the database how dose it splits by sector to see if there is a balanced obsevations from bothe Jewish And Arab sector, so I created a table:</p>
<pre class="r"><code>dim(final_df_zafon_darom)</code></pre>
<pre><code>## [1] 42111    25</code></pre>
<pre class="r"><code>table(final_df_zafon_darom$CODE_MIGZAR)</code></pre>
<pre><code>## 
##     1     2     5 
## 32714   312  9085</code></pre>
<p>From the table we can see that the north and south consists of only 312 arab students observations out of 42,111. It means that the although there are plenty of arabs in the north and the south, they are not included in the definition of south and north.</p>
</div>
<div id="regression-rest-of-the-counties-with-fixed-effects" class="section level3">
<h3>regression rest of the counties with fixed effects</h3>
<pre class="r"><code>FE.arb.rest &lt;- plm(arb.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_rest, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.arb.rest)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = arb.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_rest, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 273, T = 9-304, N = 24672
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -3.25002 -0.53417  0.16502  0.65147  2.47801 
## 
## Coefficients: (1 dropped because of singularities)
##                          Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                      0.243186   0.032759  7.4236 1.177e-13 ***
## factor(SHNAT_LIMUD)2008  0.109724   0.027828  3.9430 8.070e-05 ***
## factor(SHNAT_LIMUD)2009  0.071177   0.041941  1.6971    0.0897 .  
## factor(SHNAT_LIMUD)2015 -0.053663   0.037233 -1.4413    0.1495    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    19002
## Residual Sum of Squares: 18945
## R-Squared:      0.0029888
## Adj. R-Squared: -0.0082912
## F-statistic: 18.2827 on 4 and 24395 DF, p-value: 5.2136e-15</code></pre>
<pre class="r"><code>FE.mat.rest &lt;- plm(mat.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_rest, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.mat.rest)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = mat.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_rest, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1209, T = 1-319, N = 85433
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -3.128202 -0.608755  0.063612  0.658465  2.513085 
## 
## Coefficients: (1 dropped because of singularities)
##                          Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                     0.1603969  0.0174413  9.1964 &lt; 2.2e-16 ***
## factor(SHNAT_LIMUD)2008 0.0496210  0.0148668  3.3377 0.0008451 ***
## factor(SHNAT_LIMUD)2009 0.0687525  0.0205715  3.3421 0.0008318 ***
## factor(SHNAT_LIMUD)2015 0.0044341  0.0197375  0.2247 0.8222495    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    64000
## Residual Sum of Squares: 63930
## R-Squared:      0.0010847
## Adj. R-Squared: -0.013291
## F-statistic: 22.8625 on 4 and 84220 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.eng.rest &lt;- plm(eng.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_rest, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.eng.rest)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = eng.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_rest, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1068, T = 1-308, N = 85441
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -3.85331 -0.60585  0.11318  0.67730  3.23548 
## 
## Coefficients: (1 dropped because of singularities)
##                          Estimate Std. Error t-value Pr(&gt;|t|)   
## did                      0.034209   0.016917  2.0222 0.043160 * 
## factor(SHNAT_LIMUD)2008  0.021587   0.016738  1.2897 0.197158   
## factor(SHNAT_LIMUD)2009 -0.063396   0.020762 -3.0535 0.002263 **
## factor(SHNAT_LIMUD)2015 -0.022491   0.019869 -1.1320 0.257653   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    68060
## Residual Sum of Squares: 68030
## R-Squared:      0.00044663
## Adj. R-Squared: -0.012242
## F-statistic: 9.42465 on 4 and 84369 DF, p-value: 1.2979e-07</code></pre>
<pre class="r"><code>FE.arb.rest &lt;- plm(arb.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_rest, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.arb.rest)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = arb.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_rest, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 273, T = 9-304, N = 24672
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -3.25002 -0.53417  0.16502  0.65147  2.47801 
## 
## Coefficients: (1 dropped because of singularities)
##                          Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                      0.243186   0.032759  7.4236 1.177e-13 ***
## factor(SHNAT_LIMUD)2008  0.109724   0.027828  3.9430 8.070e-05 ***
## factor(SHNAT_LIMUD)2009  0.071177   0.041941  1.6971    0.0897 .  
## factor(SHNAT_LIMUD)2015 -0.053663   0.037233 -1.4413    0.1495    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    19002
## Residual Sum of Squares: 18945
## R-Squared:      0.0029888
## Adj. R-Squared: -0.0082912
## F-statistic: 18.2827 on 4 and 24395 DF, p-value: 5.2136e-15</code></pre>
<p>Summary table for rest of counties with fixed effects:</p>
<pre class="r"><code>stargazer(FE.arb.rest, FE.mat.rest, FE.eng.rest, FE.arb.rest, title=&quot;Year &amp; School fixed effect did regression -  rest of israel&quot;, align=TRUE, type = &quot;text&quot;)</code></pre>
<pre><code>## 
## Year &amp; School fixed effect did regression - rest of israel
## ==============================================================================================================================
##                                                                  Dependent variable:                                          
##                         ------------------------------------------------------------------------------------------------------
##                                arb.zscore                mat.zscore                eng.zscore               arb.zscore        
##                                    (1)                       (2)                      (3)                       (4)           
## ------------------------------------------------------------------------------------------------------------------------------
## did                             0.243***                  0.160***                  0.034**                  0.243***         
##                                  (0.033)                   (0.017)                  (0.017)                   (0.033)         
##                                                                                                                               
## factor(SHNAT_LIMUD)2008         0.110***                  0.050***                   0.022                   0.110***         
##                                  (0.028)                   (0.015)                  (0.017)                   (0.028)         
##                                                                                                                               
## factor(SHNAT_LIMUD)2009          0.071*                   0.069***                 -0.063***                  0.071*          
##                                  (0.042)                   (0.021)                  (0.021)                   (0.042)         
##                                                                                                                               
## factor(SHNAT_LIMUD)2015          -0.054                     0.004                    -0.022                   -0.054          
##                                  (0.037)                   (0.020)                  (0.020)                   (0.037)         
##                                                                                                                               
## ------------------------------------------------------------------------------------------------------------------------------
## Observations                     24,672                    85,433                    85,441                   24,672          
## R2                                0.003                     0.001                    0.0004                    0.003          
## Adjusted R2                      -0.008                    -0.013                    -0.012                   -0.008          
## F Statistic             18.283*** (df = 4; 24395) 22.863*** (df = 4; 84220) 9.425*** (df = 4; 84369) 18.283*** (df = 4; 24395)
## ==============================================================================================================================
## Note:                                                                                              *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
<div id="adding-variables-to-regression-and-regress-by-sectore" class="section level2">
<h2>Adding variables to regression and regress by sectore</h2>
<div id="split-the-data-by-sector" class="section level3">
<h3>Split the data by sector</h3>
<pre class="r"><code>final_df_heb &lt;- final_df %&gt;%
  filter(CODE_MIGZAR == &quot;1&quot;)
final_df_arb &lt;- final_df %&gt;%
  filter(CODE_MIGZAR != &quot;1&quot;)</code></pre>
</div>
</div>
<div id="regress-jewish-sector-only" class="section level2">
<h2>Regress Jewish sector only</h2>
<div id="convert-factor-to-numeric" class="section level3">
<h3>Convert factor to numeric</h3>
<pre class="r"><code>final_df_heb$SHNOT_LIMUD_AV &lt;- as.numeric(as.character(final_df_heb$SHNOT_LIMUD_AV))
final_df_heb$SHNOT_LIMUD_EM &lt;- as.numeric(as.character(final_df_heb$SHNOT_LIMUD_EM))</code></pre>
</div>
<div id="regression-for-jewish-sector-only" class="section level3">
<h3>Regression for jewish sector only</h3>
<pre class="r"><code>FE.heb.Hebrew.vars &lt;- plm(heb.zscore ~ did+ CODE_MIN + SHNOT_LIMUD_AV + SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD)-1, data = final_df_heb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.heb.Hebrew.vars)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = heb.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + 
##     SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + 
##     mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD) - 
##     1, data = final_df_heb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1298, T = 1-277, N = 83932
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -4.38852 -0.44476  0.17973  0.62306  2.92351 
## 
## Coefficients: (1 dropped because of singularities)
##                                      Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                                0.00565709 0.01783631  0.3172  0.751118    
## CODE_MIN                           0.28901646 0.00682205 42.3650 &lt; 2.2e-16 ***
## SHNOT_LIMUD_AV                     0.01141313 0.00079640 14.3309 &lt; 2.2e-16 ***
## SHNOT_LIMUD_EM                     0.01646605 0.00090281 18.2386 &lt; 2.2e-16 ***
## dummy_av_88                        0.11105337 0.07670047  1.4479  0.147653    
## dummy_em_88                        0.21003725 0.07932756  2.6477  0.008105 ** 
## mean_kids_per_class_by_school_year 0.00589359 0.00142364  4.1398 3.480e-05 ***
## erets_leda_ISR                     0.33521258 0.01395712 24.0173 &lt; 2.2e-16 ***
## factor(SHNAT_LIMUD)2008            0.13369874 0.01634919  8.1777 2.934e-16 ***
## factor(SHNAT_LIMUD)2009            0.03636291 0.01970311  1.8455  0.064962 .  
## factor(SHNAT_LIMUD)2015            0.00972845 0.01876449  0.5185  0.604146    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    70846
## Residual Sum of Squares: 67833
## R-Squared:      0.042528
## Adj. R-Squared: 0.027371
## F-statistic: 333.627 on 11 and 82623 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.mat.Hebrew.var &lt;- plm(mat.zscore ~ did+ CODE_MIN + SHNOT_LIMUD_AV + SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD)-1, data = final_df_heb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.mat.Hebrew.var)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = mat.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + 
##     SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + 
##     mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD) - 
##     1, data = final_df_heb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1301, T = 2-278, N = 83806
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -3.159610 -0.598939  0.082981  0.656241  2.677416 
## 
## Coefficients: (1 dropped because of singularities)
##                                       Estimate  Std. Error  t-value  Pr(&gt;|t|)
## did                                -0.00870680  0.01717357  -0.5070  0.612164
## CODE_MIN                           -0.13325320  0.00656980 -20.2827 &lt; 2.2e-16
## SHNOT_LIMUD_AV                      0.01502835  0.00076165  19.7314 &lt; 2.2e-16
## SHNOT_LIMUD_EM                      0.01868199  0.00086408  21.6207 &lt; 2.2e-16
## dummy_av_88                         0.19692103  0.07408314   2.6581  0.007860
## dummy_em_88                         0.23217405  0.07664568   3.0292  0.002453
## mean_kids_per_class_by_school_year -0.00118160  0.00137539  -0.8591  0.390286
## erets_leda_ISR                      0.11032813  0.01334441   8.2677 &lt; 2.2e-16
## factor(SHNAT_LIMUD)2008             0.13774252  0.01575335   8.7437 &lt; 2.2e-16
## factor(SHNAT_LIMUD)2009             0.08969868  0.01902307   4.7153 2.418e-06
## factor(SHNAT_LIMUD)2015             0.03131908  0.01809400   1.7309  0.083472
##                                       
## did                                   
## CODE_MIN                           ***
## SHNOT_LIMUD_AV                     ***
## SHNOT_LIMUD_EM                     ***
## dummy_av_88                        ** 
## dummy_em_88                        ** 
## mean_kids_per_class_by_school_year    
## erets_leda_ISR                     ***
## factor(SHNAT_LIMUD)2008            ***
## factor(SHNAT_LIMUD)2009            ***
## factor(SHNAT_LIMUD)2015            .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    64578
## Residual Sum of Squares: 62712
## R-Squared:      0.028895
## Adj. R-Squared: 0.013462
## F-statistic: 223.147 on 11 and 82494 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.eng.Hebrew.vars &lt;- plm(eng.zscore ~ did + did+ CODE_MIN + SHNOT_LIMUD_AV + SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD)-1, data = final_df_heb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.eng.Hebrew.vars)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = eng.zscore ~ did + did + CODE_MIN + SHNOT_LIMUD_AV + 
##     SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + 
##     mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD) - 
##     1, data = final_df_heb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1039, T = 1-295, N = 77399
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -3.79041 -0.62117  0.10561  0.68274  3.39641 
## 
## Coefficients: (1 dropped because of singularities)
##                                       Estimate  Std. Error  t-value  Pr(&gt;|t|)
## did                                -0.01020319  0.01822071  -0.5600   0.57550
## CODE_MIN                            0.01551454  0.00673701   2.3029   0.02129
## SHNOT_LIMUD_AV                      0.01190893  0.00083941  14.1873 &lt; 2.2e-16
## SHNOT_LIMUD_EM                      0.01724012  0.00095713  18.0124 &lt; 2.2e-16
## dummy_av_88                         0.11277620  0.09944839   1.1340   0.25679
## dummy_em_88                         0.20238839  0.10217656   1.9808   0.04762
## mean_kids_per_class_by_school_year -0.00630833  0.00149780  -4.2117 2.537e-05
## erets_leda_ISR                     -0.25116350  0.01399010 -17.9529 &lt; 2.2e-16
## factor(SHNAT_LIMUD)2008             0.09428764  0.01803593   5.2278 1.720e-07
## factor(SHNAT_LIMUD)2009            -0.00367298  0.02211668  -0.1661   0.86810
## factor(SHNAT_LIMUD)2015             0.05060543  0.02054684   2.4629   0.01378
##                                       
## did                                   
## CODE_MIN                           *  
## SHNOT_LIMUD_AV                     ***
## SHNOT_LIMUD_EM                     ***
## dummy_av_88                           
## dummy_em_88                        *  
## mean_kids_per_class_by_school_year ***
## erets_leda_ISR                     ***
## factor(SHNAT_LIMUD)2008            ***
## factor(SHNAT_LIMUD)2009               
## factor(SHNAT_LIMUD)2015            *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    63761
## Residual Sum of Squares: 62536
## R-Squared:      0.01921
## Adj. R-Squared: 0.0057346
## F-statistic: 135.946 on 11 and 76349 DF, p-value: &lt; 2.22e-16</code></pre>
</div>
<div id="jewish-sector-only-summary-table" class="section level3">
<h3>Jewish sector only summary table</h3>
<pre class="r"><code>stargazer(FE.heb.Hebrew.vars, FE.mat.Hebrew.var, FE.eng.Hebrew.vars, title=&quot;Fixed effects did regression with additional variables -  Jewish sector&quot;, align=TRUE, type = &quot;text&quot;)</code></pre>
<pre><code>## 
## Fixed effects did regression with additional variables - Jewish sector
## ======================================================================================================================
##                                                                    Dependent variable:                                
##                                    -----------------------------------------------------------------------------------
##                                            heb.zscore                  mat.zscore                  eng.zscore         
##                                                (1)                         (2)                         (3)            
## ----------------------------------------------------------------------------------------------------------------------
## did                                           0.006                      -0.009                      -0.010           
##                                              (0.018)                     (0.017)                     (0.018)          
##                                                                                                                       
## CODE_MIN                                    0.289***                    -0.133***                    0.016**          
##                                              (0.007)                     (0.007)                     (0.007)          
##                                                                                                                       
## SHNOT_LIMUD_AV                              0.011***                    0.015***                    0.012***          
##                                              (0.001)                     (0.001)                     (0.001)          
##                                                                                                                       
## SHNOT_LIMUD_EM                              0.016***                    0.019***                    0.017***          
##                                              (0.001)                     (0.001)                     (0.001)          
##                                                                                                                       
## dummy_av_88                                   0.111                     0.197***                      0.113           
##                                              (0.077)                     (0.074)                     (0.099)          
##                                                                                                                       
## dummy_em_88                                 0.210***                    0.232***                     0.202**          
##                                              (0.079)                     (0.077)                     (0.102)          
##                                                                                                                       
## mean_kids_per_class_by_school_year          0.006***                     -0.001                     -0.006***         
##                                              (0.001)                     (0.001)                     (0.001)          
##                                                                                                                       
## erets_leda_ISR                              0.335***                    0.110***                    -0.251***         
##                                              (0.014)                     (0.013)                     (0.014)          
##                                                                                                                       
## factor(SHNAT_LIMUD)2008                     0.134***                    0.138***                    0.094***          
##                                              (0.016)                     (0.016)                     (0.018)          
##                                                                                                                       
## factor(SHNAT_LIMUD)2009                      0.036*                     0.090***                     -0.004           
##                                              (0.020)                     (0.019)                     (0.022)          
##                                                                                                                       
## factor(SHNAT_LIMUD)2015                       0.010                      0.031*                      0.051**          
##                                              (0.019)                     (0.018)                     (0.021)          
##                                                                                                                       
## ----------------------------------------------------------------------------------------------------------------------
## Observations                                 83,932                      83,806                      77,399           
## R2                                            0.043                       0.029                       0.019           
## Adjusted R2                                   0.027                       0.013                       0.006           
## F Statistic                        333.627*** (df = 11; 82623) 223.147*** (df = 11; 82494) 135.946*** (df = 11; 76349)
## ======================================================================================================================
## Note:                                                                                      *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
<div id="arab-sector-only" class="section level2">
<h2>Arab sector only</h2>
<div id="convert-to-factor" class="section level3">
<h3>Convert to factor</h3>
<pre class="r"><code>final_df_arb$SHNOT_LIMUD_AV &lt;- as.numeric(as.character(final_df_arb$SHNOT_LIMUD_AV))
final_df_arb$SHNOT_LIMUD_EM &lt;- as.numeric(as.character(final_df_arb$SHNOT_LIMUD_EM))</code></pre>
</div>
<div id="arab-sector-only-regression" class="section level3">
<h3>Arab sector only regression</h3>
<pre class="r"><code>FE.arb.Arabic.vars &lt;- plm(arb.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD)-1, data = final_df_arb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.arb.Arabic.vars)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = arb.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + 
##     SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + 
##     mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD) - 
##     1, data = final_df_arb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 340, T = 9-304, N = 31134
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -3.40703 -0.56406  0.12798  0.64181  2.63866 
## 
## Coefficients: (1 dropped because of singularities)
##                                       Estimate  Std. Error t-value  Pr(&gt;|t|)
## did                                 0.21778718  0.03083809  7.0623 1.673e-12
## CODE_MIN                            0.50077892  0.01004319 49.8625 &lt; 2.2e-16
## SHNOT_LIMUD_AV                     -0.00201814  0.00086118 -2.3435  0.019112
## SHNOT_LIMUD_EM                     -0.00535262  0.00087837 -6.0938 1.116e-09
## dummy_av_88                        -0.18301195  0.05763995 -3.1751  0.001499
## dummy_em_88                        -0.09668845  0.06504305 -1.4865  0.137149
## mean_kids_per_class_by_school_year  0.00717858  0.00255258  2.8123  0.004922
## erets_leda_ISR                      0.01479784  0.07924781  0.1867  0.851875
## factor(SHNAT_LIMUD)2008             0.05758256  0.02915827  1.9748  0.048297
## factor(SHNAT_LIMUD)2009             0.04035708  0.04189050  0.9634  0.335357
## factor(SHNAT_LIMUD)2015            -0.15476045  0.03443561 -4.4942 7.009e-06
##                                       
## did                                ***
## CODE_MIN                           ***
## SHNOT_LIMUD_AV                     *  
## SHNOT_LIMUD_EM                     ***
## dummy_av_88                        ** 
## dummy_em_88                           
## mean_kids_per_class_by_school_year ** 
## erets_leda_ISR                        
## factor(SHNAT_LIMUD)2008            *  
## factor(SHNAT_LIMUD)2009               
## factor(SHNAT_LIMUD)2015            ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    25892
## Residual Sum of Squares: 23861
## R-Squared:      0.07843
## Adj. R-Squared: 0.067952
## F-statistic: 238.162 on 11 and 30783 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.mat.Arabic.vars &lt;- plm(mat.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD)-1, data = final_df_arb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.mat.Arabic.vars)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = mat.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + 
##     SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + 
##     mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD) - 
##     1, data = final_df_arb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 341, T = 9-319, N = 31094
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -2.846482 -0.619551  0.006909  0.621665  2.683269 
## 
## Coefficients: (1 dropped because of singularities)
##                                       Estimate  Std. Error t-value  Pr(&gt;|t|)
## did                                 0.12901408  0.02965242  4.3509 1.360e-05
## CODE_MIN                            0.13096205  0.00962530 13.6060 &lt; 2.2e-16
## SHNOT_LIMUD_AV                     -0.00048509  0.00082462 -0.5883  0.556364
## SHNOT_LIMUD_EM                     -0.00209568  0.00084221 -2.4883  0.012840
## dummy_av_88                        -0.05771452  0.05520315 -1.0455  0.295803
## dummy_em_88                        -0.33141800  0.06279623 -5.2777 1.317e-07
## mean_kids_per_class_by_school_year  0.00365933  0.00256739  1.4253  0.154077
## erets_leda_ISR                     -0.06675568  0.07626030 -0.8754  0.381382
## factor(SHNAT_LIMUD)2008            -0.17680789  0.02794663 -6.3266 2.540e-10
## factor(SHNAT_LIMUD)2009            -0.11571714  0.04101316 -2.8215  0.004784
## factor(SHNAT_LIMUD)2015            -0.22091313  0.03401044 -6.4954 8.405e-11
##                                       
## did                                ***
## CODE_MIN                           ***
## SHNOT_LIMUD_AV                        
## SHNOT_LIMUD_EM                     *  
## dummy_av_88                           
## dummy_em_88                        ***
## mean_kids_per_class_by_school_year    
## erets_leda_ISR                        
## factor(SHNAT_LIMUD)2008            ***
## factor(SHNAT_LIMUD)2009            ** 
## factor(SHNAT_LIMUD)2015            ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    22185
## Residual Sum of Squares: 21870
## R-Squared:      0.014195
## Adj. R-Squared: 0.0029394
## F-statistic: 40.2421 on 11 and 30742 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.eng.Arabic.vars &lt;- plm(eng.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD)-1, data = final_df_arb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.eng.Arabic.vars)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = eng.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + 
##     SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + 
##     mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD) - 
##     1, data = final_df_arb, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 358, T = 5-308, N = 32335
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -3.211031 -0.581873  0.091393  0.644143  2.653969 
## 
## Coefficients: (1 dropped because of singularities)
##                                       Estimate  Std. Error t-value  Pr(&gt;|t|)
## did                                 0.11596220  0.03254326  3.5633 0.0003667
## CODE_MIN                            0.25391975  0.00979652 25.9194 &lt; 2.2e-16
## SHNOT_LIMUD_AV                     -0.00029821  0.00083992 -0.3550 0.7225612
## SHNOT_LIMUD_EM                     -0.00131115  0.00087682 -1.4953 0.1348344
## dummy_av_88                        -0.17216419  0.05839577 -2.9482 0.0031983
## dummy_em_88                        -0.03342405  0.06644818 -0.5030 0.6149612
## mean_kids_per_class_by_school_year -0.00703685  0.00279372 -2.5188 0.0117800
## erets_leda_ISR                     -0.37080384  0.07815839 -4.7443 2.102e-06
## factor(SHNAT_LIMUD)2008            -0.04434071  0.03903015 -1.1361 0.2559388
## factor(SHNAT_LIMUD)2009            -0.16387428  0.04148890 -3.9498 7.837e-05
## factor(SHNAT_LIMUD)2015            -0.11253887  0.03434003 -3.2772 0.0010496
##                                       
## did                                ***
## CODE_MIN                           ***
## SHNOT_LIMUD_AV                        
## SHNOT_LIMUD_EM                        
## dummy_av_88                        ** 
## dummy_em_88                           
## mean_kids_per_class_by_school_year *  
## erets_leda_ISR                     ***
## factor(SHNAT_LIMUD)2008               
## factor(SHNAT_LIMUD)2009            ***
## factor(SHNAT_LIMUD)2015            ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    25208
## Residual Sum of Squares: 24520
## R-Squared:      0.027316
## Adj. R-Squared: 0.016118
## F-statistic: 81.6083 on 11 and 31966 DF, p-value: &lt; 2.22e-16</code></pre>
</div>
<div id="arab-only-summary-table" class="section level3">
<h3>Arab only summary table</h3>
<pre class="r"><code>stargazer(FE.arb.Arabic.vars, FE.mat.Arabic.vars, FE.eng.Arabic.vars, title=&quot;Fixed effects did regression with additional variables -  Arab sector&quot;, align=TRUE, type = &quot;text&quot;)</code></pre>
<pre><code>## 
## Fixed effects did regression with additional variables - Arab sector
## ====================================================================================================================
##                                                                   Dependent variable:                               
##                                    ---------------------------------------------------------------------------------
##                                            arb.zscore                  mat.zscore                 eng.zscore        
##                                                (1)                        (2)                        (3)            
## --------------------------------------------------------------------------------------------------------------------
## did                                         0.218***                    0.129***                   0.116***         
##                                              (0.031)                    (0.030)                    (0.033)          
##                                                                                                                     
## CODE_MIN                                    0.501***                    0.131***                   0.254***         
##                                              (0.010)                    (0.010)                    (0.010)          
##                                                                                                                     
## SHNOT_LIMUD_AV                              -0.002**                    -0.0005                    -0.0003          
##                                              (0.001)                    (0.001)                    (0.001)          
##                                                                                                                     
## SHNOT_LIMUD_EM                              -0.005***                   -0.002**                    -0.001          
##                                              (0.001)                    (0.001)                    (0.001)          
##                                                                                                                     
## dummy_av_88                                 -0.183***                    -0.058                   -0.172***         
##                                              (0.058)                    (0.055)                    (0.058)          
##                                                                                                                     
## dummy_em_88                                  -0.097                    -0.331***                    -0.033          
##                                              (0.065)                    (0.063)                    (0.066)          
##                                                                                                                     
## mean_kids_per_class_by_school_year          0.007***                     0.004                     -0.007**         
##                                              (0.003)                    (0.003)                    (0.003)          
##                                                                                                                     
## erets_leda_ISR                                0.015                      -0.067                   -0.371***         
##                                              (0.079)                    (0.076)                    (0.078)          
##                                                                                                                     
## factor(SHNAT_LIMUD)2008                      0.058**                   -0.177***                    -0.044          
##                                              (0.029)                    (0.028)                    (0.039)          
##                                                                                                                     
## factor(SHNAT_LIMUD)2009                       0.040                    -0.116***                  -0.164***         
##                                              (0.042)                    (0.041)                    (0.041)          
##                                                                                                                     
## factor(SHNAT_LIMUD)2015                     -0.155***                  -0.221***                  -0.113***         
##                                              (0.034)                    (0.034)                    (0.034)          
##                                                                                                                     
## --------------------------------------------------------------------------------------------------------------------
## Observations                                 31,134                      31,094                     32,335          
## R2                                            0.078                      0.014                      0.027           
## Adjusted R2                                   0.068                      0.003                      0.016           
## F Statistic                        238.162*** (df = 11; 30783) 40.242*** (df = 11; 30742) 81.608*** (df = 11; 31966)
## ====================================================================================================================
## Note:                                                                                    *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
<div id="regression-based-on-language-speaking-schools-different-from-code_migzar---double-check-for-effect-by-sector" class="section level2">
<h2>Regression based on language speaking schools (Different from Code_migzar) - Double check for effect by sector</h2>
<div id="inspect-language-variable" class="section level3">
<h3>Inspect language variable</h3>
<pre class="r"><code>table(clean_full_df$CODE_SFAT_LIMUDIM)</code></pre>
<pre><code>## 
##      1      2 
## 123959  47537</code></pre>
</div>
<div id="split-data-by-languages" class="section level3">
<h3>Split data by languages</h3>
<pre class="r"><code>names(clean_full_df)</code></pre>
<pre><code>##  [1] &quot;X.4&quot;                                &quot;X.3&quot;                               
##  [3] &quot;X.2&quot;                                &quot;X.1&quot;                               
##  [5] &quot;CODE_MOSAD&quot;                         &quot;CODE_ZEHUT_TALMID&quot;                 
##  [7] &quot;heb.zscore&quot;                         &quot;mat.zscore&quot;                        
##  [9] &quot;eng.zscore&quot;                         &quot;arb.zscore&quot;                        
## [11] &quot;SHNAT_LIMUD&quot;                        &quot;CODE_MIN&quot;                          
## [13] &quot;CODE_LEOM&quot;                          &quot;SHNOT_LIMUD_AV&quot;                    
## [15] &quot;SHNOT_LIMUD_EM&quot;                     &quot;CODE_MIGZAR&quot;                       
## [17] &quot;CODE_SFAT_LIMUDIM&quot;                  &quot;CODE_MACHOZ_GEOGRAFI&quot;              
## [19] &quot;treat&quot;                              &quot;after&quot;                             
## [21] &quot;did&quot;                                &quot;mean_tipuah&quot;                       
## [23] &quot;tipuah_group&quot;                       &quot;dummy_year_2008&quot;                   
## [25] &quot;dummy_year_2009&quot;                    &quot;dummy_year_2015&quot;                   
## [27] &quot;dummy_year_2016&quot;                    &quot;X&quot;                                 
## [29] &quot;mean_kids_per_class_by_school_year&quot; &quot;ERETS_LEDA&quot;                        
## [31] &quot;erets_leda_ISR&quot;                     &quot;dummy_av_88&quot;                       
## [33] &quot;dummy_em_88&quot;</code></pre>
<pre class="r"><code>final_df_hebrew &lt;- clean_full_df %&gt;%
  filter(CODE_SFAT_LIMUDIM == &quot;1&quot;)
final_df_arbic &lt;- clean_full_df %&gt;%
  filter(CODE_SFAT_LIMUDIM == &quot;2&quot;)</code></pre>
</div>
</div>
<div id="run-hebrew-language-regression" class="section level2">
<h2>Run Hebrew language regression</h2>
<pre class="r"><code>FE.heb.Hebrew.lang &lt;- plm(heb.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_hebrew, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.heb.Hebrew.lang)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = heb.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_hebrew, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1301, T = 1-277, N = 84027
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -4.23589 -0.45069  0.19277  0.64580  2.95124 
## 
## Coefficients: (1 dropped because of singularities)
##                           Estimate Std. Error t-value Pr(&gt;|t|)    
## did                     -0.0017185  0.0181695 -0.0946   0.9246    
## factor(SHNAT_LIMUD)2008  0.1204372  0.0166748  7.2227 5.14e-13 ***
## factor(SHNAT_LIMUD)2009  0.0327138  0.0201121  1.6266   0.1038    
## factor(SHNAT_LIMUD)2015 -0.0003424  0.0190969 -0.0179   0.9857    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    70911
## Residual Sum of Squares: 70838
## R-Squared:      0.0010368
## Adj. R-Squared: -0.01471
## F-statistic: 21.4644 on 4 and 82722 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.mat.Hebrew.lang &lt;- plm(mat.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_hebrew, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.mat.Hebrew.lang)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = mat.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_hebrew, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1305, T = 1-278, N = 84021
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -3.128202 -0.613150  0.081036  0.672553  2.899328 
## 
## Coefficients: (1 dropped because of singularities)
##                           Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                     -0.0081571  0.0173540 -0.4700    0.6383    
## factor(SHNAT_LIMUD)2008  0.1296811  0.0159498  8.1306 4.331e-16 ***
## factor(SHNAT_LIMUD)2009  0.0949765  0.0192733  4.9279 8.329e-07 ***
## factor(SHNAT_LIMUD)2015  0.0410401  0.0182586  2.2477    0.0246 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    64776
## Residual Sum of Squares: 64671
## R-Squared:      0.0016147
## Adj. R-Squared: -0.014174
## F-statistic: 33.4434 on 4 and 82712 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.eng.Hebrew.lang &lt;- plm(eng.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_hebrew, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.eng.Hebrew.lang)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = eng.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_hebrew, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1042, T = 1-295, N = 77448
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -3.89413 -0.62723  0.10847  0.69251  3.23548 
## 
## Coefficients: (1 dropped because of singularities)
##                           Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                     -0.0297297  0.0183594 -1.6193 0.1053836    
## factor(SHNAT_LIMUD)2008  0.0876089  0.0179851  4.8712 1.111e-06 ***
## factor(SHNAT_LIMUD)2009 -0.0012627  0.0221305 -0.0571 0.9544989    
## factor(SHNAT_LIMUD)2015  0.0724867  0.0207116  3.4998 0.0004658 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    63774
## Residual Sum of Squares: 63718
## R-Squared:      0.00087027
## Adj. R-Squared: -0.012795
## F-statistic: 16.637 on 4 and 76402 DF, p-value: 1.2307e-13</code></pre>
<div id="hebrew-speaking-analysis-summary-table" class="section level3">
<h3>Hebrew speaking analysis summary table</h3>
<pre class="r"><code>stargazer(FE.heb.Hebrew.lang, FE.mat.Hebrew.lang, FE.eng.Hebrew.lang, title=&quot;Year &amp; School fixed effect did regression -  Hebrew language&quot;, align=TRUE, type = &quot;text&quot;)</code></pre>
<pre><code>## 
## Year &amp; School fixed effect did regression - Hebrew language
## =====================================================================================================
##                                                      Dependent variable:                             
##                         -----------------------------------------------------------------------------
##                                heb.zscore                mat.zscore                eng.zscore        
##                                    (1)                       (2)                       (3)           
## -----------------------------------------------------------------------------------------------------
## did                              -0.002                    -0.008                    -0.030          
##                                  (0.018)                   (0.017)                   (0.018)         
##                                                                                                      
## factor(SHNAT_LIMUD)2008         0.120***                  0.130***                  0.088***         
##                                  (0.017)                   (0.016)                   (0.018)         
##                                                                                                      
## factor(SHNAT_LIMUD)2009           0.033                   0.095***                   -0.001          
##                                  (0.020)                   (0.019)                   (0.022)         
##                                                                                                      
## factor(SHNAT_LIMUD)2015          -0.0003                   0.041**                  0.072***         
##                                  (0.019)                   (0.018)                   (0.021)         
##                                                                                                      
## -----------------------------------------------------------------------------------------------------
## Observations                     84,027                    84,021                    77,448          
## R2                                0.001                     0.002                     0.001          
## Adjusted R2                      -0.015                    -0.014                    -0.013          
## F Statistic             21.464*** (df = 4; 82722) 33.443*** (df = 4; 82712) 16.637*** (df = 4; 76402)
## =====================================================================================================
## Note:                                                                     *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
<div id="run-arabic-language-regression-analysis" class="section level2">
<h2>Run Arabic language regression analysis</h2>
<pre class="r"><code>FE.arb.Arabic.lang &lt;- plm(arb.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_arbic, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.arb.Arabic.lang)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = arb.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_arbic, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 339, T = 9-304, N = 31033
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -3.25002 -0.59062  0.15092  0.67830  2.49810 
## 
## Coefficients: (1 dropped because of singularities)
##                          Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                      0.202843   0.032073  6.3245 2.575e-10 ***
## factor(SHNAT_LIMUD)2008  0.066360   0.028411  2.3357   0.01951 *  
## factor(SHNAT_LIMUD)2009  0.066747   0.041606  1.6043   0.10867    
## factor(SHNAT_LIMUD)2015 -0.152923   0.035857 -4.2648 2.007e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    25814
## Residual Sum of Squares: 25761
## R-Squared:      0.0020653
## Adj. R-Squared: -0.0090554
## F-statistic: 15.8789 on 4 and 30690 DF, p-value: 5.4512e-13</code></pre>
<pre class="r"><code>FE.mat.Arabic.lang &lt;- plm(mat.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_arbic, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.mat.Arabic.lang)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = mat.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_arbic, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 344, T = 9-319, N = 31055
## 
## Residuals:
##       Min.    1st Qu.     Median    3rd Qu.       Max. 
## -2.7768906 -0.6203591  0.0082244  0.6179386  2.5781383 
## 
## Coefficients: (1 dropped because of singularities)
##                          Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                      0.120370   0.029669  4.0571 4.980e-05 ***
## factor(SHNAT_LIMUD)2008 -0.175375   0.026199 -6.6938 2.211e-11 ***
## factor(SHNAT_LIMUD)2009 -0.098142   0.038981 -2.5177   0.01182 *  
## factor(SHNAT_LIMUD)2015 -0.232465   0.034086 -6.8199 9.278e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    22099
## Residual Sum of Squares: 21951
## R-Squared:      0.0067248
## Adj. R-Squared: -0.0044996
## F-statistic: 51.9739 on 4 and 30707 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.eng.Arabic.lang &lt;- plm(eng.zscore ~ did + factor(SHNAT_LIMUD)-1, data = final_df_arbic, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.eng.Arabic.lang)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = eng.zscore ~ did + factor(SHNAT_LIMUD) - 1, data = final_df_arbic, 
##     model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 358, T = 5-308, N = 32347
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -3.240557 -0.584190  0.095993  0.657710  2.590821 
## 
## Coefficients: (1 dropped because of singularities)
##                          Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                      0.106394   0.032531  3.2705  0.001075 ** 
## factor(SHNAT_LIMUD)2008 -0.084476   0.036134 -2.3378  0.019402 *  
## factor(SHNAT_LIMUD)2009 -0.207188   0.038491 -5.3828 7.386e-08 ***
## factor(SHNAT_LIMUD)2015 -0.119608   0.034749 -3.4421  0.000578 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    25254
## Residual Sum of Squares: 25117
## R-Squared:      0.0054229
## Adj. R-Squared: -0.0058024
## F-statistic: 43.5997 on 4 and 31985 DF, p-value: &lt; 2.22e-16</code></pre>
<div id="arabic-speaking-analysis-summary-table" class="section level3">
<h3>Arabic speaking analysis summary table</h3>
<pre class="r"><code>stargazer(FE.arb.Arabic.lang, FE.mat.Arabic.lang, FE.eng.Arabic.lang, title=&quot;Year &amp; School fixed effect did regression -  Arabic language&quot;, align=TRUE, type = &quot;text&quot;)</code></pre>
<pre><code>## 
## Year &amp; School fixed effect did regression - Arabic language
## =====================================================================================================
##                                                      Dependent variable:                             
##                         -----------------------------------------------------------------------------
##                                arb.zscore                mat.zscore                eng.zscore        
##                                    (1)                       (2)                       (3)           
## -----------------------------------------------------------------------------------------------------
## did                             0.203***                  0.120***                  0.106***         
##                                  (0.032)                   (0.030)                   (0.033)         
##                                                                                                      
## factor(SHNAT_LIMUD)2008          0.066**                  -0.175***                 -0.084**         
##                                  (0.028)                   (0.026)                   (0.036)         
##                                                                                                      
## factor(SHNAT_LIMUD)2009           0.067                   -0.098**                  -0.207***        
##                                  (0.042)                   (0.039)                   (0.038)         
##                                                                                                      
## factor(SHNAT_LIMUD)2015         -0.153***                 -0.232***                 -0.120***        
##                                  (0.036)                   (0.034)                   (0.035)         
##                                                                                                      
## -----------------------------------------------------------------------------------------------------
## Observations                     31,033                    31,055                    32,347          
## R2                                0.002                     0.007                     0.005          
## Adjusted R2                      -0.009                    -0.004                    -0.006          
## F Statistic             15.879*** (df = 4; 30690) 51.974*** (df = 4; 30707) 43.600*** (df = 4; 31985)
## =====================================================================================================
## Note:                                                                     *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
</div>
<div id="it-seems-like-the-influence-is-stronger-for-arabic-sector-when-adding-fixed-effects-additional-variables" class="section level1">
<h1>It seems like the influence is stronger for arabic sector when adding fixed effects &amp; additional variables</h1>
<div id="now-run-by-language-again-with-additional-variables" class="section level2">
<h2>Now, Run by language again with additional variables</h2>
<div id="hebrew-speaking" class="section level3">
<h3>Hebrew speaking</h3>
<pre class="r"><code>FE.heb.Hebrew.vars.lang &lt;- plm(heb.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD)-1, data = final_df_hebrew, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.heb.Hebrew.vars.lang)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = heb.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + 
##     SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + 
##     mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD) - 
##     1, data = final_df_hebrew, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1294, T = 1-277, N = 83866
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -4.38877 -0.44460  0.17993  0.62303  2.92353 
## 
## Coefficients: (1 dropped because of singularities)
##                                      Estimate Std. Error t-value  Pr(&gt;|t|)    
## did                                0.00564489 0.01783590  0.3165   0.75163    
## CODE_MIN                           0.28901776 0.00682189 42.3662 &lt; 2.2e-16 ***
## SHNOT_LIMUD_AV                     0.01142779 0.00079680 14.3421 &lt; 2.2e-16 ***
## SHNOT_LIMUD_EM                     0.01644244 0.00090314 18.2058 &lt; 2.2e-16 ***
## dummy_av_88                        0.10712102 0.07695644  1.3920   0.16394    
## dummy_em_88                        0.21312535 0.07949246  2.6811   0.00734 ** 
## mean_kids_per_class_by_school_year 0.00589336 0.00142361  4.1397 3.480e-05 ***
## erets_leda_ISR                     0.33535960 0.01396275 24.0182 &lt; 2.2e-16 ***
## factor(SHNAT_LIMUD)2008            0.13370582 0.01634881  8.1783 2.919e-16 ***
## factor(SHNAT_LIMUD)2009            0.03637600 0.01970266  1.8462   0.06486 .  
## factor(SHNAT_LIMUD)2015            0.00974976 0.01876407  0.5196   0.60335    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    70791
## Residual Sum of Squares: 67778
## R-Squared:      0.042549
## Adj. R-Squared: 0.027426
## F-statistic: 333.544 on 11 and 82561 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.mat.Hebrew.vars.lang &lt;- plm(mat.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD)-1, data = final_df_hebrew, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.mat.Hebrew.vars.lang)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = mat.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + 
##     SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + 
##     mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD) - 
##     1, data = final_df_hebrew, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1298, T = 2-278, N = 83845
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -3.159535 -0.599671  0.083369  0.656692  2.673874 
## 
## Coefficients: (1 dropped because of singularities)
##                                       Estimate  Std. Error  t-value  Pr(&gt;|t|)
## did                                -0.00246668  0.01716709  -0.1437  0.885748
## CODE_MIN                           -0.13264016  0.00656877 -20.1925 &lt; 2.2e-16
## SHNOT_LIMUD_AV                      0.01493264  0.00076071  19.6299 &lt; 2.2e-16
## SHNOT_LIMUD_EM                      0.01857916  0.00086267  21.5368 &lt; 2.2e-16
## dummy_av_88                         0.22048862  0.07282380   3.0277  0.002465
## dummy_em_88                         0.18449948  0.07510879   2.4564  0.014035
## mean_kids_per_class_by_school_year -0.00057383  0.00137437  -0.4175  0.676299
## erets_leda_ISR                      0.11098410  0.01335624   8.3095 &lt; 2.2e-16
## factor(SHNAT_LIMUD)2008             0.14157848  0.01575544   8.9860 &lt; 2.2e-16
## factor(SHNAT_LIMUD)2009             0.09060530  0.01903339   4.7603 1.936e-06
## factor(SHNAT_LIMUD)2015             0.03742864  0.01808970   2.0691  0.038544
##                                       
## did                                   
## CODE_MIN                           ***
## SHNOT_LIMUD_AV                     ***
## SHNOT_LIMUD_EM                     ***
## dummy_av_88                        ** 
## dummy_em_88                        *  
## mean_kids_per_class_by_school_year    
## erets_leda_ISR                     ***
## factor(SHNAT_LIMUD)2008            ***
## factor(SHNAT_LIMUD)2009            ***
## factor(SHNAT_LIMUD)2015            *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    64664
## Residual Sum of Squares: 62815
## R-Squared:      0.028596
## Adj. R-Squared: 0.013201
## F-statistic: 220.879 on 11 and 82536 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.eng.Hebrew.vars.lang &lt;- plm(eng.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD)-1, data = final_df_hebrew, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.eng.Hebrew.vars.lang)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = eng.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + 
##     SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + 
##     mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD) - 
##     1, data = final_df_hebrew, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 1039, T = 1-295, N = 77387
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -3.79052 -0.62092  0.10564  0.68240  3.39652 
## 
## Coefficients: (1 dropped because of singularities)
##                                       Estimate  Std. Error  t-value  Pr(&gt;|t|)
## did                                -0.01023150  0.01821553  -0.5617   0.57433
## CODE_MIN                            0.01545776  0.00673271   2.2959   0.02168
## SHNOT_LIMUD_AV                      0.01188234  0.00083840  14.1726 &lt; 2.2e-16
## SHNOT_LIMUD_EM                      0.01724524  0.00095573  18.0440 &lt; 2.2e-16
## dummy_av_88                         0.08718797  0.09881380   0.8823   0.37759
## dummy_em_88                         0.22665154  0.10165316   2.2297   0.02577
## mean_kids_per_class_by_school_year -0.00630868  0.00149733  -4.2133 2.520e-05
## erets_leda_ISR                     -0.25113685  0.01398945 -17.9519 &lt; 2.2e-16
## factor(SHNAT_LIMUD)2008             0.09430057  0.01803034   5.2301 1.699e-07
## factor(SHNAT_LIMUD)2009            -0.00367121  0.02210740  -0.1661   0.86811
## factor(SHNAT_LIMUD)2015             0.05062937  0.02053594   2.4654   0.01369
##                                       
## did                                   
## CODE_MIN                           *  
## SHNOT_LIMUD_AV                     ***
## SHNOT_LIMUD_EM                     ***
## dummy_av_88                           
## dummy_em_88                        *  
## mean_kids_per_class_by_school_year ***
## erets_leda_ISR                     ***
## factor(SHNAT_LIMUD)2008            ***
## factor(SHNAT_LIMUD)2009               
## factor(SHNAT_LIMUD)2015            *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    63716
## Residual Sum of Squares: 62491
## R-Squared:      0.01922
## Adj. R-Squared: 0.0057427
## F-statistic: 135.997 on 11 and 76337 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>stargazer(FE.heb.Hebrew.vars.lang, FE.mat.Hebrew.vars.lang, FE.eng.Hebrew.vars.lang, title=&quot;Year &amp; School fixed effect did regression with variables -  Hebrew language&quot;, align=TRUE, type = &quot;text&quot;)</code></pre>
<pre><code>## 
## Year &amp; School fixed effect did regression with variables - Hebrew language
## ======================================================================================================================
##                                                                    Dependent variable:                                
##                                    -----------------------------------------------------------------------------------
##                                            heb.zscore                  mat.zscore                  eng.zscore         
##                                                (1)                         (2)                         (3)            
## ----------------------------------------------------------------------------------------------------------------------
## did                                           0.006                      -0.002                      -0.010           
##                                              (0.018)                     (0.017)                     (0.018)          
##                                                                                                                       
## CODE_MIN                                    0.289***                    -0.133***                    0.015**          
##                                              (0.007)                     (0.007)                     (0.007)          
##                                                                                                                       
## SHNOT_LIMUD_AV                              0.011***                    0.015***                    0.012***          
##                                              (0.001)                     (0.001)                     (0.001)          
##                                                                                                                       
## SHNOT_LIMUD_EM                              0.016***                    0.019***                    0.017***          
##                                              (0.001)                     (0.001)                     (0.001)          
##                                                                                                                       
## dummy_av_88                                   0.107                     0.220***                      0.087           
##                                              (0.077)                     (0.073)                     (0.099)          
##                                                                                                                       
## dummy_em_88                                 0.213***                     0.184**                     0.227**          
##                                              (0.079)                     (0.075)                     (0.102)          
##                                                                                                                       
## mean_kids_per_class_by_school_year          0.006***                     -0.001                     -0.006***         
##                                              (0.001)                     (0.001)                     (0.001)          
##                                                                                                                       
## erets_leda_ISR                              0.335***                    0.111***                    -0.251***         
##                                              (0.014)                     (0.013)                     (0.014)          
##                                                                                                                       
## factor(SHNAT_LIMUD)2008                     0.134***                    0.142***                    0.094***          
##                                              (0.016)                     (0.016)                     (0.018)          
##                                                                                                                       
## factor(SHNAT_LIMUD)2009                      0.036*                     0.091***                     -0.004           
##                                              (0.020)                     (0.019)                     (0.022)          
##                                                                                                                       
## factor(SHNAT_LIMUD)2015                       0.010                      0.037**                     0.051**          
##                                              (0.019)                     (0.018)                     (0.021)          
##                                                                                                                       
## ----------------------------------------------------------------------------------------------------------------------
## Observations                                 83,866                      83,845                      77,387           
## R2                                            0.043                       0.029                       0.019           
## Adjusted R2                                   0.027                       0.013                       0.006           
## F Statistic                        333.544*** (df = 11; 82561) 220.879*** (df = 11; 82536) 135.997*** (df = 11; 76337)
## ======================================================================================================================
## Note:                                                                                      *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
<div id="arabic-speaking" class="section level3">
<h3>Arabic speaking</h3>
<pre class="r"><code>FE.arb.Arabic.vars.lang &lt;- plm(arb.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD)-1, data = final_df_arbic, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.arb.Arabic.vars.lang)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = arb.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + 
##     SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + 
##     mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD) - 
##     1, data = final_df_arbic, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 339, T = 9-304, N = 31033
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -3.40326 -0.56426  0.12828  0.64256  2.64026 
## 
## Coefficients: (1 dropped because of singularities)
##                                       Estimate  Std. Error t-value  Pr(&gt;|t|)
## did                                 0.21687814  0.03085540  7.0289 2.126e-12
## CODE_MIN                            0.50041287  0.01006148 49.7355 &lt; 2.2e-16
## SHNOT_LIMUD_AV                     -0.00219398  0.00086363 -2.5404 0.0110768
## SHNOT_LIMUD_EM                     -0.00533298  0.00088061 -6.0560 1.412e-09
## dummy_av_88                        -0.19231180  0.05825871 -3.3010 0.0009645
## dummy_em_88                        -0.10090263  0.06622261 -1.5237 0.1275969
## mean_kids_per_class_by_school_year  0.00687710  0.00258022  2.6653 0.0076956
## erets_leda_ISR                      0.00963565  0.07957882  0.1211 0.9036260
## factor(SHNAT_LIMUD)2008             0.05839079  0.02917358  2.0015 0.0453478
## factor(SHNAT_LIMUD)2009             0.04165102  0.04192774  0.9934 0.3205228
## factor(SHNAT_LIMUD)2015            -0.15647740  0.03450027 -4.5355 5.767e-06
##                                       
## did                                ***
## CODE_MIN                           ***
## SHNOT_LIMUD_AV                     *  
## SHNOT_LIMUD_EM                     ***
## dummy_av_88                        ***
## dummy_em_88                           
## mean_kids_per_class_by_school_year ** 
## erets_leda_ISR                        
## factor(SHNAT_LIMUD)2008            *  
## factor(SHNAT_LIMUD)2009               
## factor(SHNAT_LIMUD)2015            ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    25814
## Residual Sum of Squares: 23792
## R-Squared:      0.078336
## Adj. R-Squared: 0.067852
## F-statistic: 237.078 on 11 and 30683 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.mat.Arabic.vars.lang &lt;- plm(mat.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD)-1, data = final_df_arbic, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.mat.Arabic.vars.lang)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = mat.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + 
##     SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + 
##     mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD) - 
##     1, data = final_df_arbic, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 344, T = 9-319, N = 31055
## 
## Residuals:
##       Min.    1st Qu.     Median    3rd Qu.       Max. 
## -2.8494035 -0.6179274  0.0072892  0.6205471  2.6595781 
## 
## Coefficients: (1 dropped because of singularities)
##                                       Estimate  Std. Error t-value  Pr(&gt;|t|)
## did                                 0.12381305  0.02962657  4.1791 2.934e-05
## CODE_MIN                            0.13049960  0.00963063 13.5505 &lt; 2.2e-16
## SHNOT_LIMUD_AV                     -0.00043155  0.00082563 -0.5227    0.6012
## SHNOT_LIMUD_EM                     -0.00211366  0.00084327 -2.5065    0.0122
## dummy_av_88                        -0.06312079  0.05574158 -1.1324    0.2575
## dummy_em_88                        -0.30481884  0.06401380 -4.7618 1.928e-06
## mean_kids_per_class_by_school_year  0.00058943  0.00259484  0.2272    0.8203
## erets_leda_ISR                     -0.07826631  0.07529011 -1.0395    0.2986
## factor(SHNAT_LIMUD)2008            -0.17052318  0.02792760 -6.1059 1.034e-09
## factor(SHNAT_LIMUD)2009            -0.10218838  0.04100525 -2.4921    0.0127
## factor(SHNAT_LIMUD)2015            -0.23668113  0.03403273 -6.9545 3.609e-12
##                                       
## did                                ***
## CODE_MIN                           ***
## SHNOT_LIMUD_AV                        
## SHNOT_LIMUD_EM                     *  
## dummy_av_88                           
## dummy_em_88                        ***
## mean_kids_per_class_by_school_year    
## erets_leda_ISR                        
## factor(SHNAT_LIMUD)2008            ***
## factor(SHNAT_LIMUD)2009            *  
## factor(SHNAT_LIMUD)2015            ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    22099
## Residual Sum of Squares: 21791
## R-Squared:      0.013937
## Adj. R-Squared: 0.0025663
## F-statistic: 39.4455 on 11 and 30700 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>FE.eng.Arabic.vars.lang &lt;- plm(eng.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD)-1, data = final_df_arbic, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
summary(FE.eng.Arabic.vars.lang)</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = eng.zscore ~ did + CODE_MIN + SHNOT_LIMUD_AV + 
##     SHNOT_LIMUD_EM + dummy_av_88 + dummy_em_88 + mean_tipuah + 
##     mean_kids_per_class_by_school_year + erets_leda_ISR + factor(SHNAT_LIMUD) - 
##     1, data = final_df_arbic, model = &quot;within&quot;, index = &quot;CODE_MOSAD&quot;)
## 
## Unbalanced Panel: n = 358, T = 5-308, N = 32347
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -3.211801 -0.582660  0.091165  0.645660  2.654293 
## 
## Coefficients: (1 dropped because of singularities)
##                                       Estimate  Std. Error t-value  Pr(&gt;|t|)
## did                                 0.11587842  0.03256711  3.5581  0.000374
## CODE_MIN                            0.25448094  0.00981140 25.9373 &lt; 2.2e-16
## SHNOT_LIMUD_AV                     -0.00029657  0.00084127 -0.3525  0.724444
## SHNOT_LIMUD_EM                     -0.00134660  0.00087834 -1.5331  0.125254
## dummy_av_88                        -0.16374462  0.05860399 -2.7941  0.005208
## dummy_em_88                        -0.04438772  0.06668708 -0.6656  0.505664
## mean_kids_per_class_by_school_year -0.00701745  0.00279611 -2.5097  0.012088
## erets_leda_ISR                     -0.36972747  0.07761664 -4.7635 1.911e-06
## factor(SHNAT_LIMUD)2008            -0.04455200  0.03906220 -1.1405  0.254070
## factor(SHNAT_LIMUD)2009            -0.16435931  0.04154065 -3.9566 7.619e-05
## factor(SHNAT_LIMUD)2015            -0.11305460  0.03439061 -3.2874  0.001012
##                                       
## did                                ***
## CODE_MIN                           ***
## SHNOT_LIMUD_AV                        
## SHNOT_LIMUD_EM                        
## dummy_av_88                        ** 
## dummy_em_88                           
## mean_kids_per_class_by_school_year *  
## erets_leda_ISR                     ***
## factor(SHNAT_LIMUD)2008               
## factor(SHNAT_LIMUD)2009            ***
## factor(SHNAT_LIMUD)2015            ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    25254
## Residual Sum of Squares: 24564
## R-Squared:      0.02732
## Adj. R-Squared: 0.016126
## F-statistic: 81.6516 on 11 and 31978 DF, p-value: &lt; 2.22e-16</code></pre>
<pre class="r"><code>stargazer(FE.arb.Arabic.vars.lang, FE.mat.Arabic.vars.lang, FE.eng.Arabic.vars.lang, title=&quot;Year &amp; School fixed effect did regression with variables -  Arabic language&quot;, align=TRUE, type = &quot;text&quot;)</code></pre>
<pre><code>## 
## Year &amp; School fixed effect did regression with variables - Arabic language
## ====================================================================================================================
##                                                                   Dependent variable:                               
##                                    ---------------------------------------------------------------------------------
##                                            arb.zscore                  mat.zscore                 eng.zscore        
##                                                (1)                        (2)                        (3)            
## --------------------------------------------------------------------------------------------------------------------
## did                                         0.217***                    0.124***                   0.116***         
##                                              (0.031)                    (0.030)                    (0.033)          
##                                                                                                                     
## CODE_MIN                                    0.500***                    0.130***                   0.254***         
##                                              (0.010)                    (0.010)                    (0.010)          
##                                                                                                                     
## SHNOT_LIMUD_AV                              -0.002**                    -0.0004                    -0.0003          
##                                              (0.001)                    (0.001)                    (0.001)          
##                                                                                                                     
## SHNOT_LIMUD_EM                              -0.005***                   -0.002**                    -0.001          
##                                              (0.001)                    (0.001)                    (0.001)          
##                                                                                                                     
## dummy_av_88                                 -0.192***                    -0.063                   -0.164***         
##                                              (0.058)                    (0.056)                    (0.059)          
##                                                                                                                     
## dummy_em_88                                  -0.101                    -0.305***                    -0.044          
##                                              (0.066)                    (0.064)                    (0.067)          
##                                                                                                                     
## mean_kids_per_class_by_school_year          0.007***                     0.001                     -0.007**         
##                                              (0.003)                    (0.003)                    (0.003)          
##                                                                                                                     
## erets_leda_ISR                                0.010                      -0.078                   -0.370***         
##                                              (0.080)                    (0.075)                    (0.078)          
##                                                                                                                     
## factor(SHNAT_LIMUD)2008                      0.058**                   -0.171***                    -0.045          
##                                              (0.029)                    (0.028)                    (0.039)          
##                                                                                                                     
## factor(SHNAT_LIMUD)2009                       0.042                     -0.102**                  -0.164***         
##                                              (0.042)                    (0.041)                    (0.042)          
##                                                                                                                     
## factor(SHNAT_LIMUD)2015                     -0.156***                  -0.237***                  -0.113***         
##                                              (0.035)                    (0.034)                    (0.034)          
##                                                                                                                     
## --------------------------------------------------------------------------------------------------------------------
## Observations                                 31,033                      31,055                     32,347          
## R2                                            0.078                      0.014                      0.027           
## Adjusted R2                                   0.068                      0.003                      0.016           
## F Statistic                        237.078*** (df = 11; 30683) 39.445*** (df = 11; 30700) 81.652*** (df = 11; 31978)
## ====================================================================================================================
## Note:                                                                                    *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
